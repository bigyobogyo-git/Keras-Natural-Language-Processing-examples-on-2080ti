{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "503efff3-4c52-493e-98a6-3401fa9d94a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-06 14:52:50.326619: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1762437170.338264   15968 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1762437170.341760   15968 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1762437170.352253   15968 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1762437170.352262   15968 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1762437170.352264   15968 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1762437170.352265   15968 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-11-06 14:52:50.355510: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"KERAS_BACKEND\"] = \"tensorflow\"\n",
    "\n",
    "import keras_hub\n",
    "import keras\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import time\n",
    "\n",
    "keras.mixed_precision.set_global_policy(\"mixed_float16\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cc042171-0d58-4244-9da4-029372914cec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# General hyperparameters\n",
    "BATCH_SIZE = 16\n",
    "NUM_BATCHES = 500\n",
    "EPOCHS = 1  # Can be set to a higher value for better results\n",
    "MAX_SEQUENCE_LENGTH = 128\n",
    "MAX_GENERATION_LENGTH = 200\n",
    "\n",
    "GPT2_PRESET = \"gpt2_base_en\"\n",
    "\n",
    "# LoRA-specific hyperparameters\n",
    "RANK = 4\n",
    "ALPHA = 32.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "357d3fe0-e794-48cb-9a73-721a19c33110",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1762437176.478477   15968 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 8923 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2080 Ti, pci bus id: 0000:08:00.0, compute capability: 7.5\n"
     ]
    }
   ],
   "source": [
    "reddit_ds = tfds.load(\"reddit_tifu\", split=\"train\", as_supervised=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "27176c16-1f44-4071-b211-e91efd291936",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b\"me and a friend decided to go to the beach last sunday. we loaded up and headed out. we were about half way there when i decided that i was not leaving till i had seafood. \\n\\nnow i'm not talking about red lobster. no friends i'm talking about a low country boil. i found the restaurant and got directions. i don't know if any of you have heard about the crab shack on tybee island but let me tell you it's worth it. \\n\\nwe arrived and was seated quickly. we decided to get a seafood sampler for two and split it. the waitress bought it out on separate platters for us. the amount of food was staggering. two types of crab, shrimp, mussels, crawfish, andouille sausage, red potatoes, and corn on the cob. i managed to finish it and some of my friends crawfish and mussels. it was a day to be a fat ass. we finished paid for our food and headed to the beach. \\n\\nfunny thing about seafood. it runs through me faster than a kenyan \\n\\nwe arrived and walked around a bit. it was about 45min since we arrived at the beach when i felt a rumble from the depths of my stomach. i ignored it i didn't want my stomach to ruin our fun. i pushed down the feeling and continued. about 15min later the feeling was back and stronger than before. again i ignored it and continued. 5min later it felt like a nuclear reactor had just exploded in my stomach. i started running. i yelled to my friend to hurry the fuck up. \\n\\nrunning in sand is extremely hard if you did not know this. we got in his car and i yelled at him to floor it. my stomach was screaming and if he didn't hurry i was gonna have this baby in his car and it wasn't gonna be pretty. after a few red lights and me screaming like a woman in labor we made it to the store. \\n\\ni practically tore his car door open and ran inside. i ran to the bathroom opened the door and barely got my pants down before the dam burst and a flood of shit poured from my ass. \\n\\ni finished up when i felt something wet on my ass. i rubbed it thinking it was back splash. no, mass was covered in the after math of me abusing the toilet. i grabbed all the paper towels i could and gave my self a whores bath right there. \\n\\ni sprayed the bathroom down with the air freshener and left. an elderly lady walked in quickly and closed the door. i was just about to walk away when i heard gag. instead of walking i ran. i got to the car and told him to get the hell out of there.\"\n",
      "b'liking seafood'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-06 14:52:56.668378: I tensorflow/core/kernels/data/tf_record_dataset_op.cc:387] The default buffer size is 262144, which is overridden by the user specified `buffer_size` of 8388608\n",
      "2025-11-06 14:52:56.673938: W tensorflow/core/kernels/data/cache_dataset_ops.cc:916] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    }
   ],
   "source": [
    "for document, title in reddit_ds:\n",
    "    print(document.numpy())\n",
    "    print(title.numpy())\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4c3a0a1b-bd01-4499-8dd8-55b441328df9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = (\n",
    "    reddit_ds.map(lambda document, _: document)\n",
    "    .batch(BATCH_SIZE)\n",
    "    .cache()\n",
    "    .prefetch(tf.data.AUTOTUNE)\n",
    ")\n",
    "train_ds = train_ds.take(NUM_BATCHES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4a009a77-09fe-4ce0-9db6-32d7f253efdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GPUMemoryCallback(keras.callbacks.Callback):\n",
    "    def __init__(\n",
    "        self,\n",
    "        target_batches,\n",
    "        print_stats=False,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        super().__init__(**kwargs)\n",
    "        self.target_batches = target_batches\n",
    "        self.print_stats = print_stats\n",
    "\n",
    "        self.memory_usage = []\n",
    "        self.labels = []\n",
    "\n",
    "    def _compute_memory_usage(self):\n",
    "        memory_stats = tf.config.experimental.get_memory_info(\"GPU:0\")\n",
    "        # Convert bytes to GB and store in list.\n",
    "        peak_usage = round(memory_stats[\"peak\"] / (2**30), 3)\n",
    "        self.memory_usage.append(peak_usage)\n",
    "\n",
    "    def on_epoch_begin(self, epoch, logs=None):\n",
    "        self._compute_memory_usage()\n",
    "        self.labels.append(f\"epoch {epoch} start\")\n",
    "\n",
    "    def on_train_batch_begin(self, batch, logs=None):\n",
    "        if batch in self.target_batches:\n",
    "            self._compute_memory_usage()\n",
    "            self.labels.append(f\"batch {batch}\")\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        self._compute_memory_usage()\n",
    "        self.labels.append(f\"epoch {epoch} end\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cfe421fe-0548-499b-b84a-5c9eb3fe74f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(model, input_text, max_length=200):\n",
    "    start = time.time()\n",
    "\n",
    "    output = model.generate(input_text, max_length=max_length)\n",
    "    print(\"\\nOutput:\")\n",
    "    print(output)\n",
    "\n",
    "    end = time.time()\n",
    "    print(f\"Total Time Elapsed: {end - start:.2f}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "16413914-bece-4957-825c-125447edf695",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_optimizer_and_loss():\n",
    "    optimizer = keras.optimizers.AdamW(\n",
    "        learning_rate=5e-5,\n",
    "        weight_decay=0.01,\n",
    "        epsilon=1e-6,\n",
    "        global_clipnorm=1.0,  # Gradient clipping.\n",
    "    )\n",
    "    # Exclude layernorm and bias terms from weight decay.\n",
    "    optimizer.exclude_from_weight_decay(var_names=[\"bias\"])\n",
    "    optimizer.exclude_from_weight_decay(var_names=[\"gamma\"])\n",
    "    optimizer.exclude_from_weight_decay(var_names=[\"beta\"])\n",
    "\n",
    "    loss = keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "    return optimizer, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6fabcbe4-7999-4d96-82f0-f7161af7b53b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Preprocessor: \"gpt2_causal_lm_preprocessor\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mPreprocessor: \"gpt2_causal_lm_preprocessor\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                                                  </span>┃<span style=\"font-weight: bold\">                                   Config </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ gpt2_tokenizer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GPT2Tokenizer</span>)                                │                       Vocab size: <span style=\"color: #00af00; text-decoration-color: #00af00\">50,257</span> │\n",
       "└───────────────────────────────────────────────────────────────┴──────────────────────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                                                 \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m                                  Config\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ gpt2_tokenizer (\u001b[38;5;33mGPT2Tokenizer\u001b[0m)                                │                       Vocab size: \u001b[38;5;34m50,257\u001b[0m │\n",
       "└───────────────────────────────────────────────────────────────┴──────────────────────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"gpt2_causal_lm\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"gpt2_causal_lm\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                  </span>┃<span style=\"font-weight: bold\"> Output Shape              </span>┃<span style=\"font-weight: bold\">         Param # </span>┃<span style=\"font-weight: bold\"> Connected to               </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ padding_mask (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ token_ids (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ gpt2_backbone (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GPT2Backbone</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>)         │     <span style=\"color: #00af00; text-decoration-color: #00af00\">124,439,808</span> │ padding_mask[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],        │\n",
       "│                               │                           │                 │ token_ids[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ token_embedding               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50257</span>)       │      <span style=\"color: #00af00; text-decoration-color: #00af00\">38,597,376</span> │ gpt2_backbone[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReversibleEmbedding</span>)         │                           │                 │                            │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                 \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to              \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ padding_mask (\u001b[38;5;33mInputLayer\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ token_ids (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ gpt2_backbone (\u001b[38;5;33mGPT2Backbone\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m768\u001b[0m)         │     \u001b[38;5;34m124,439,808\u001b[0m │ padding_mask[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],        │\n",
       "│                               │                           │                 │ token_ids[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ token_embedding               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50257\u001b[0m)       │      \u001b[38;5;34m38,597,376\u001b[0m │ gpt2_backbone[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
       "│ (\u001b[38;5;33mReversibleEmbedding\u001b[0m)         │                           │                 │                            │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">124,439,808</span> (474.70 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m124,439,808\u001b[0m (474.70 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">124,439,808</span> (474.70 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m124,439,808\u001b[0m (474.70 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "preprocessor = keras_hub.models.GPT2CausalLMPreprocessor.from_preset(\n",
    "    \"gpt2_base_en\",\n",
    "    sequence_length=MAX_SEQUENCE_LENGTH,\n",
    ")\n",
    "gpt2_lm = keras_hub.models.GPT2CausalLM.from_preset(\n",
    "    \"gpt2_base_en\", preprocessor=preprocessor\n",
    ")\n",
    "\n",
    "gpt2_lm.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1699ad2d-60eb-4cae-afbf-ee66dc408fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu_memory_callback = GPUMemoryCallback(\n",
    "    target_batches=[5, 10, 25, 50, 100, 150, 200, 300, 400, 500],\n",
    "    print_stats=True,\n",
    ")\n",
    "\n",
    "optimizer, loss = get_optimizer_and_loss()\n",
    "\n",
    "gpt2_lm.compile(\n",
    "    optimizer=optimizer,\n",
    "    loss=loss,\n",
    "    weighted_metrics=[\"accuracy\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "29f52df9-df17-42cb-974b-b6c98b49c85a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1762437198.575780   16083 service.cc:152] XLA service 0x71f754069c80 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1762437198.575809   16083 service.cc:160]   StreamExecutor device (0): NVIDIA GeForce RTX 2080 Ti, Compute Capability 7.5\n",
      "2025-11-06 14:53:19.006663: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2025-11-06 14:53:19.486042: W tensorflow/compiler/tf2xla/kernels/assert_op.cc:39] Ignoring Assert operator compile_loss/sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/assert_equal_1/Assert/Assert\n",
      "I0000 00:00:1762437202.509471   16083 cuda_dnn.cc:529] Loaded cuDNN version 91002\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m  1/500\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m5:35:27\u001b[0m 40s/step - accuracy: 0.2884 - loss: 3.9084"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1762437221.364476   16083 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m484/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m2s\u001b[0m 153ms/step - accuracy: 0.3090 - loss: 3.4181"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-06 14:54:55.372843: W tensorflow/core/kernels/data/cache_dataset_ops.cc:916] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2025-11-06 14:54:55.373985: W tensorflow/core/kernels/data/cache_dataset_ops.cc:916] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m117s\u001b[0m 154ms/step - accuracy: 0.3170 - loss: 3.3554\n"
     ]
    }
   ],
   "source": [
    "gpt2_lm.fit(train_ds, epochs=EPOCHS, callbacks=[gpu_memory_callback])\n",
    "gpt2_lm_memory_usage = gpu_memory_callback.memory_usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7d99ae65-b50f-452d-91cd-ce897a3789d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Output:\n",
      "I like basketball. \n",
      "\n",
      "so i have a friend that loves to play basketball. \n",
      "\n",
      "so this morning he came up to my room and started playing basketball, which is a little different than basketball. \n",
      "\n",
      "my friend starts playing basketball and i start playing with him. \n",
      "\n",
      "so i play with him and he starts playing basketball, so i start playing basketball. \n",
      "\n",
      "i start playing with him and he starts playing basketball with me, so i'm like okay. \n",
      "\n",
      "my friend says, \"hey, what's going on? \n",
      "Total Time Elapsed: 7.26s\n",
      "\n",
      "Output:\n",
      "That Italian restaurant is located at a strip mall and they're all about serving food and drinks. \n",
      "\n",
      "i'm in the middle of eating a delicious pizza and the pizza comes out of the oven with a pizza crust on top. i'm in a hurry to get my food to the pizza oven, so i grab a pizza crust from one of the tables and begin to roll it over. i'm about to roll it over and it just falls to the floor in a heap, but i'm still trying to roll it over so i can get the pizza to my mouth. \n",
      "\n",
      "i'm trying to roll it under\n",
      "Total Time Elapsed: 0.75s\n"
     ]
    }
   ],
   "source": [
    "generate_text(gpt2_lm, \"I like basketball\", max_length=MAX_GENERATION_LENGTH)\n",
    "generate_text(gpt2_lm, \"That Italian restaurant is\", max_length=MAX_GENERATION_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6a4db0d4-0a6a-4483-9002-fddaf5bb9020",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "\n",
    "class LoraLayer(keras.layers.Layer):\n",
    "    def __init__(\n",
    "        self,\n",
    "        original_layer,\n",
    "        rank=8,\n",
    "        alpha=32,\n",
    "        trainable=False,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        # We want to keep the name of this layer the same as the original\n",
    "        # dense layer.\n",
    "        original_layer_config = original_layer.get_config()\n",
    "        name = original_layer_config[\"name\"]\n",
    "\n",
    "        kwargs.pop(\"name\", None)\n",
    "\n",
    "        super().__init__(name=name, trainable=trainable, **kwargs)\n",
    "\n",
    "        self.rank = rank\n",
    "        self.alpha = alpha\n",
    "\n",
    "        self._scale = alpha / rank\n",
    "\n",
    "        self._num_heads = original_layer_config[\"output_shape\"][-2]\n",
    "        self._hidden_dim = self._num_heads * original_layer_config[\"output_shape\"][-1]\n",
    "\n",
    "        # Layers.\n",
    "\n",
    "        # Original dense layer.\n",
    "        self.original_layer = original_layer\n",
    "        # No matter whether we are training the model or are in inference mode,\n",
    "        # this layer should be frozen.\n",
    "        self.original_layer.trainable = False\n",
    "\n",
    "        # LoRA dense layers.\n",
    "        self.A = keras.layers.Dense(\n",
    "            units=rank,\n",
    "            use_bias=False,\n",
    "            # Note: the original paper mentions that normal distribution was\n",
    "            # used for initialization. However, the official LoRA implementation\n",
    "            # uses \"Kaiming/He Initialization\".\n",
    "            kernel_initializer=keras.initializers.VarianceScaling(\n",
    "                scale=math.sqrt(5), mode=\"fan_in\", distribution=\"uniform\"\n",
    "            ),\n",
    "            trainable=trainable,\n",
    "            name=f\"lora_A\",\n",
    "        )\n",
    "        # B has the same `equation` and `output_shape` as the original layer.\n",
    "        # `equation = abc,cde->abde`, where `a`: batch size, `b`: sequence\n",
    "        # length, `c`: `hidden_dim`, `d`: `num_heads`,\n",
    "        # `e`: `hidden_dim//num_heads`. The only difference is that in layer `B`,\n",
    "        # `c` represents `rank`.\n",
    "        self.B = keras.layers.EinsumDense(\n",
    "            equation=original_layer_config[\"equation\"],\n",
    "            output_shape=original_layer_config[\"output_shape\"],\n",
    "            kernel_initializer=\"zeros\",\n",
    "            trainable=trainable,\n",
    "            name=f\"lora_B\",\n",
    "        )\n",
    "\n",
    "    def call(self, inputs):\n",
    "        original_output = self.original_layer(inputs)\n",
    "        if self.trainable:\n",
    "            # If we are fine-tuning the model, we will add LoRA layers' output\n",
    "            # to the original layer's output.\n",
    "            lora_output = self.B(self.A(inputs)) * self._scale\n",
    "            return original_output + lora_output\n",
    "\n",
    "        # If we are in inference mode, we \"merge\" the LoRA layers' weights into\n",
    "        # the original layer's weights - more on this in the text generation\n",
    "        # section!\n",
    "        return original_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d46d27ee-806b-48ee-8233-2c9123ca309f",
   "metadata": {},
   "outputs": [],
   "source": [
    "del gpt2_lm\n",
    "del optimizer\n",
    "del loss\n",
    "\n",
    "# This resets \"peak\" memory usage to \"current\" memory usage.\n",
    "tf.config.experimental.reset_memory_stats(\"GPU:0\")\n",
    "\n",
    "# Load the original model.\n",
    "preprocessor = keras_hub.models.GPT2CausalLMPreprocessor.from_preset(\n",
    "    \"gpt2_base_en\",\n",
    "    sequence_length=128,\n",
    ")\n",
    "lora_model = keras_hub.models.GPT2CausalLM.from_preset(\n",
    "    \"gpt2_base_en\",\n",
    "    preprocessor=preprocessor,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3ca1e870-3c61-4c43-a4c8-f513b69d4168",
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer_idx in range(lora_model.backbone.num_layers):\n",
    "    # Change query dense layer.\n",
    "    decoder_layer = lora_model.backbone.get_layer(f\"transformer_layer_{layer_idx}\")\n",
    "    self_attention_layer = decoder_layer._self_attention_layer\n",
    "    # Allow mutation to Keras layer state.\n",
    "    self_attention_layer._tracker.locked = False\n",
    "\n",
    "    # Change query dense layer.\n",
    "    self_attention_layer._query_dense = LoraLayer(\n",
    "        self_attention_layer._query_dense,\n",
    "        rank=RANK,\n",
    "        alpha=ALPHA,\n",
    "        trainable=True,\n",
    "    )\n",
    "\n",
    "    # Change value dense layer.\n",
    "    self_attention_layer._value_dense = LoraLayer(\n",
    "        self_attention_layer._value_dense,\n",
    "        rank=RANK,\n",
    "        alpha=ALPHA,\n",
    "        trainable=True,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "39fde813-6d48-4ee4-8f3f-9a8ce434c100",
   "metadata": {},
   "outputs": [],
   "source": [
    "lora_model(preprocessor([\"LoRA is very useful for quick LLM finetuning\"])[0])\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "41d3e0d1-ec74-41d3-8de5-f709052a55c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in lora_model._flatten_layers():\n",
    "    lst_of_sublayers = list(layer._flatten_layers())\n",
    "\n",
    "    if len(lst_of_sublayers) == 1:  # \"leaves of the model\"\n",
    "        if layer.name in [\"lora_A\", \"lora_B\"]:\n",
    "            layer.trainable = True\n",
    "        else:\n",
    "            layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "93633120-ab12-49df-9f75-5401bfc3b81f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Preprocessor: \"gpt2_causal_lm_preprocessor_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mPreprocessor: \"gpt2_causal_lm_preprocessor_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                                                  </span>┃<span style=\"font-weight: bold\">                                   Config </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ gpt2_tokenizer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GPT2Tokenizer</span>)                                │                       Vocab size: <span style=\"color: #00af00; text-decoration-color: #00af00\">50,257</span> │\n",
       "└───────────────────────────────────────────────────────────────┴──────────────────────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                                                 \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m                                  Config\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ gpt2_tokenizer (\u001b[38;5;33mGPT2Tokenizer\u001b[0m)                                │                       Vocab size: \u001b[38;5;34m50,257\u001b[0m │\n",
       "└───────────────────────────────────────────────────────────────┴──────────────────────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"gpt2_causal_lm_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"gpt2_causal_lm_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                  </span>┃<span style=\"font-weight: bold\"> Output Shape              </span>┃<span style=\"font-weight: bold\">         Param # </span>┃<span style=\"font-weight: bold\"> Connected to               </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ padding_mask (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ token_ids (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ gpt2_backbone (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GPT2Backbone</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>)         │     <span style=\"color: #00af00; text-decoration-color: #00af00\">124,587,264</span> │ padding_mask[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],        │\n",
       "│                               │                           │                 │ token_ids[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ token_embedding               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50257</span>)       │      <span style=\"color: #00af00; text-decoration-color: #00af00\">38,597,376</span> │ gpt2_backbone[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReversibleEmbedding</span>)         │                           │                 │                            │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                 \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to              \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ padding_mask (\u001b[38;5;33mInputLayer\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ token_ids (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ gpt2_backbone (\u001b[38;5;33mGPT2Backbone\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m768\u001b[0m)         │     \u001b[38;5;34m124,587,264\u001b[0m │ padding_mask[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],        │\n",
       "│                               │                           │                 │ token_ids[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ token_embedding               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50257\u001b[0m)       │      \u001b[38;5;34m38,597,376\u001b[0m │ gpt2_backbone[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
       "│ (\u001b[38;5;33mReversibleEmbedding\u001b[0m)         │                           │                 │                            │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">124,587,264</span> (475.26 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m124,587,264\u001b[0m (475.26 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">147,456</span> (576.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m147,456\u001b[0m (576.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">124,439,808</span> (474.70 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m124,439,808\u001b[0m (474.70 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lora_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5ca79c5a-31bf-4725-9242-685586cb82e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-06 14:57:32.141125: W tensorflow/compiler/tf2xla/kernels/assert_op.cc:39] Ignoring Assert operator compile_loss/sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/assert_equal_1/Assert/Assert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m484/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m1s\u001b[0m 90ms/step - accuracy: 0.2851 - loss: 3.6705"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-06 14:58:26.628227: W tensorflow/core/kernels/data/cache_dataset_ops.cc:916] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2025-11-06 14:58:26.629383: W tensorflow/core/kernels/data/cache_dataset_ops.cc:916] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 91ms/step - accuracy: 0.2921 - loss: 3.5878\n"
     ]
    }
   ],
   "source": [
    "gpu_memory_callback = GPUMemoryCallback(\n",
    "    target_batches=[5, 10, 25, 50, 100, 150, 200, 300, 400, 500],\n",
    "    print_stats=True,\n",
    ")\n",
    "\n",
    "optimizer, loss = get_optimizer_and_loss()\n",
    "\n",
    "lora_model.compile(\n",
    "    optimizer=optimizer,\n",
    "    loss=loss,\n",
    "    weighted_metrics=[\"accuracy\"],\n",
    ")\n",
    "\n",
    "lora_model.fit(\n",
    "    train_ds,\n",
    "    epochs=EPOCHS,\n",
    "    callbacks=[gpu_memory_callback],\n",
    ")\n",
    "lora_model_memory_usage = gpu_memory_callback.memory_usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "20a59ba4-a3f9-4936-9a04-92a9110aec3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_15968/1400903047.py:11: UserWarning: No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n",
      "  plt.legend()\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAioAAAHHCAYAAACRAnNyAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAPy9JREFUeJzt3XlcVHX////nALKJ7CAuCCouKbiUaWqlpUlaWqaZZuaWH3NN7bK0TOPKIitbVTI1tcsl0yzTcmnBXS+XLm0xzQVNTXMFBBQFzu+PvszPEdAZHJqjPO6329xuzvu855zXDOPhyTnv8z4WwzAMAQAAmJCbqwsAAAAoCkEFAACYFkEFAACYFkEFAACYFkEFAACYFkEFAACYFkEFAACYFkEFAACYFkEFAACYFkEFAOCQWbNmyWKx6ODBg64uBaUAQQWmkpKSosGDB6tmzZry9fWVr6+v6tSpo0GDBumnn36y6fvyyy/LYrFYH/l9x4wZo/T09AL9Tp06Veg2Y2Nj1bJly2vWFh0dLYvFotatWxe6fNq0adZatm3bZv+bvolYLBYNHjy40GWLFi2SxWLR6tWr/9miSsgXX3yhtm3bKjQ0VJ6enqpYsaK6dOmiH374wdWlATcVD1cXAORbtmyZHnvsMXl4eKh79+6qX7++3NzctHv3bi1evFhJSUlKSUlRVFSUzeuSkpLk5+enjIwMrVq1Sq+++qp++OEHbdiwQRaLxak1ent7Kzk5WcePH1dERITNsrlz58rb21sXLlxw6jZhLoZhqE+fPpo1a5YaNmyoESNGKCIiQseOHdMXX3yhVq1aacOGDWrWrJmrSy0xPXr0UNeuXeXl5eXqUlAKEFRgCvv371fXrl0VFRWl77//XhUqVLBZPmHCBE2ZMkVubgUPAnbu3FmhoaGSpKefflqdOnXS4sWLtXnzZjVt2tSpdTZv3lxbt27VggUL9Mwzz1jbjxw5onXr1qljx476/PPPnbrNf0JeXp4uXrwob29vV5diehMnTtSsWbM0bNgwvf322zZh+MUXX9R//vMfeXjcnLvWzMxMlS1bVu7u7nJ3d3d1OSglOPUDU3jjjTeUmZmpmTNnFggpkuTh4aGhQ4cqMjLymuu69957Jf19GsnZvL299cgjj2jevHk27fPnz1dQUJDi4+MLfd3u3bvVuXNnBQcHy9vbW40aNdJXX31l0yf/vP/69es1dOhQhYWFKTAwUP3799fFixeVmpqqJ598UkFBQQoKCtJzzz2nK29+npmZqWeffVaRkZHy8vJSrVq19NZbbxXol3+KZu7cuapbt668vLy0fPlyRUdH66GHHipQ/4ULFxQQEKD+/fsX52Mr0t69e9WpUydFRETI29tblStXVteuXZWWlmbtM3PmTN17770KDw+Xl5eX6tSpo6SkpALrysvL08svv6yKFSvK19dX99xzj3bt2qXo6Gj16tXLpm9qaqqGDRtm/ZxiYmI0YcIE5eXlXbXe8+fPKzExUbVr19Zbb71V6BG7Hj16qHHjxtbnBw4c0KOPPqrg4GD5+vrqjjvu0Ndff23zmtWrV8tiseizzz5TQkKCKlWqpHLlyqlz585KS0tTdna2hg0bpvDwcPn5+al3797Kzs62WcflP9NatWrJ29tbt912m9auXWvT79ChQxo4cKBq1aolHx8fhYSE6NFHHy0w3iT/+7hmzRoNHDhQ4eHhqly5ss2yy1+zbds2xcfHKzQ0VD4+Pqpatar69Oljs05Hv59ffvmlYmNj5eXlpbp162rFihVX/fng5nRzxn7ccJYtW6aYmBg1adLkute1f/9+SVJISMh1r6swjz/+uNq0aaP9+/erevXqkqR58+apc+fOKlOmTIH+v/76q5o3b65KlSpp1KhRKlu2rD777DM9/PDD+vzzz9WxY0eb/kOGDFFERIQSEhK0efNmffTRRwoMDNTGjRtVpUoVvfbaa/rmm2/05ptvKjY2Vk8++aSkv09JdOjQQcnJyerbt68aNGiglStXauTIkTp69Kjeeecdm+388MMP+uyzzzR48GCFhoaqatWqeuKJJ/TGG2/ozJkzCg4OtvZdunSp0tPT9cQTTzjtc7x48aLi4+OVnZ1tfc9Hjx7VsmXLlJqaqoCAAEl/n9qrW7euOnToIA8PDy1dulQDBw5UXl6eBg0aZF3f6NGj9cYbb6h9+/aKj4/Xzp07FR8fX+BUXFZWllq0aKGjR4+qf//+qlKlijZu3KjRo0fr2LFjevfdd4usef369Tpz5oyGDRtm1xGFv/76S82aNVNWVpaGDh2qkJAQzZ49Wx06dNCiRYsK/OwTExPl4+OjUaNGad++ffrggw9UpkwZubm56ezZs3r55Ze1efNmzZo1S1WrVtXYsWNtXr9mzRotWLBAQ4cOlZeXl6ZMmaL7779fW7ZsUWxsrCRp69at2rhxo7p27arKlSvr4MGDSkpKUsuWLbVr1y75+vrarHPgwIEKCwvT2LFjlZmZWej7PHHihNq0aaOwsDCNGjVKgYGBOnjwoBYvXmzt4+j3c/369Vq8eLEGDhyocuXK6f3331enTp30xx9/lNj/bZiUAbhYWlqaIcl4+OGHCyw7e/ascfLkSesjKyvLumzcuHGGJGPPnj3GyZMnjZSUFGPq1KmGl5eXUb58eSMzM9Om38mTJwvdft26dY0WLVpcs86oqCjjgQceMHJycoyIiAjjlVdeMQzDMHbt2mVIMtasWWPMnDnTkGRs3brV+rpWrVoZcXFxxoULF6xteXl5RrNmzYwaNWpY2/JfGx8fb+Tl5VnbmzZtalgsFuPpp5+2tuXk5BiVK1e2qfvLL780JBnjx4+3qbtz586GxWIx9u3bZ22TZLi5uRm//vqrTd89e/YYkoykpCSb9g4dOhjR0dE2dRVGkjFo0KBCly1cuNCQZCQnJxuGYRj/+9//DEnGwoULr7rOy3/m+eLj441q1apZnx8/ftzw8PAo8B16+eWXDUlGz549rW2vvPKKUbZsWeP333+36Ttq1CjD3d3d+OOPP4qs5b333jMkGV988cVVa843bNgwQ5Kxbt06a9u5c+eMqlWrGtHR0UZubq5hGIaRnJxsSDJiY2ONixcvWvt269bNsFgsRtu2bW3W27RpUyMqKsqmTZIhydi2bZu17dChQ4a3t7fRsWNHa1thn+emTZsMScYnn3xibcv/Pt55551GTk6OTf/8ZSkpKYZhGMYXX3xR4Ht/JUe/n56enjZtO3fuNCQZH3zwQZHbwM2JUz9wufwrdPz8/Aosa9mypcLCwqyPyZMnF+hTq1YthYWFqWrVqurfv79iYmL09ddfF/jL0Fnc3d3VpUsXzZ8/X9Lfg2gjIyN11113Feh75swZ/fDDD+rSpYvOnTunU6dO6dSpUzp9+rTi4+O1d+9eHT161OY1ffv2tTml0KRJExmGob59+9rU0KhRIx04cMDa9s0338jd3V1Dhw61Wd+zzz4rwzC0fPlym/YWLVqoTp06Nm01a9ZUkyZNNHfuXJv3sHz5cnXv3t2pg5Pzj5isXLlSWVlZRfbz8fGx/jstLU2nTp1SixYtdODAAespou+//145OTkaOHCgzWuHDBlSYH0LFy7UXXfdpaCgIOvP49SpU2rdurVyc3MLnCq5XP53tVy5cna9x2+++UaNGzfWnXfeaW3z8/PT//3f/+ngwYPatWuXTf8nn3zS5qhc/s/+ylMoTZo00eHDh5WTk2PT3rRpU912223W51WqVNFDDz2klStXKjc3V5Lt53np0iWdPn1aMTExCgwM1I8//ljgPfTr1++aR48CAwMl/X1k9NKlS4X2cfT72bp1a+sRS0mqV6+e/P39bb7zKB0IKnC5/J1+RkZGgWVTp07Vt99+qzlz5hT5+s8//1zffvutVq9erX379umXX36x2Vnbw9FfwI8//rh27dqlnTt3at68eeratWuh69i3b58Mw9BLL71kE7jCwsI0btw4SX8fNr9clSpVbJ7n/0K/cnxOQECAzp49a31+6NAhVaxYscAv0VtuucW6/HJVq1Yt9L09+eST2rBhg7X/woULdenSJfXo0aPwD8NB+Z9T1apVNWLECE2fPl2hoaGKj4/X5MmTbcanSNKGDRvUunVrlS1bVoGBgQoLC9MLL7wgSda++bXGxMTYvDY4OFhBQUE2bXv37tWKFSsK/DzyLzu/8udxOX9/f0nSuXPn7Hqvhw4dUq1atQq0F/UzceRnn5eXV+CzqlGjRoFt1axZU1lZWTp58qSkv8fZjB071jpOJDQ0VGFhYUpNTS2wPqno78nlWrRooU6dOikhIUGhoaF66KGHNHPmTJtxNI5+P6/8LCQpKCjI5juP0oExKnC5gIAAVahQQb/88kuBZfljVq42sdTdd99tveqnMPlXspw/f77Q5VlZWQ5f7dKkSRNVr15dw4YNU0pKih5//PFC++UPzvzXv/5V5EDbK3+5FvXXa2HtxhWDEB1x+V/Wl+vatauGDx+uuXPn6oUXXtCcOXPUqFGjQn/hXsnLy+uqn7Mkm8964sSJ6tWrl5YsWaJVq1Zp6NChSkxM1ObNm1W5cmXt379frVq1Uu3atfX2228rMjJSnp6e+uabb/TOO+9cc/BrYfLy8nTffffpueeeK3R5zZo1i3xt7dq1JUk///yzHn74YYe3fS2O/Oyl4v38hwwZopkzZ2rYsGFq2rSpAgICZLFY1LVr10I/z6K+J5ezWCxatGiRNm/erKVLl2rlypXq06ePJk6cqM2bNxd6tPRanPmecWMjqMAUHnjgAU2fPl1btmyxuWLCGfLnXdmzZ0+Bv0yzsrJ0+PBhtWnTxuH1duvWTePHj9ctt9yiBg0aFNqnWrVqkqQyZcoUOVGcs0RFRem7777TuXPnbP5q3b17t3W5PYKDg/XAAw9o7ty56t69uzZs2HDVAaZX1rBnz55Cl+W3X1lHXFyc4uLiNGbMGG3cuFHNmzfXhx9+qPHjx2vp0qXKzs7WV199ZfMXdnJycoHtSn8fwbr8CMDp06cL/AVevXp1ZWRkFOvnceeddyooKEjz58/XCy+8cM1TIkV9Ho7+TOy1d+/eAm2///67fH19FRYWJunvifd69uypiRMnWvtcuHBBqamp1739O+64Q3fccYdeffVVzZs3T927d9enn36qp556ymnfT5Q+nPqBKTz33HPy9fVVnz599NdffxVYfj1/RbVq1Uqenp5KSkoq8BfjRx99pJycHLVt29bh9T711FMaN26czQ7/SuHh4WrZsqWmTp2qY8eOFViefzjeGdq1a6fc3FxNmjTJpv2dd96RxWJx6D326NFDu3bt0siRI+Xu7q6uXbvaXcPmzZu1fft2m/bU1FTNnTtXDRo0sE6Ul56eXmCMRVxcnNzc3KynDPKDwOU//7S0NM2cOdPmda1atZKHh0eBy5av/CwkqUuXLtq0aZNWrlxZYFlqamqBmi7n6+ur559/Xr/99puef/75Qr+Xc+bM0ZYtWyT9/Xls2bJFmzZtsi7PzMzURx99pOjo6AJjhK7Xpk2bbMaZHD58WEuWLFGbNm2sn6W7u3uBuj/44APrGJbiOHv2bIF15of3/J+lM7+fKF04ogJTqFGjhubNm6du3bqpVq1a1plpDcNQSkqK5s2bJzc3N+s8Do4IDw/X2LFjNWbMGN19993q0KGDfH19tXHjRs2fP19t2rRR+/btHV5vVFSUXn755Wv2mzx5su68807FxcWpX79+qlatmv766y9t2rRJR44c0c6dOx3edmHat2+ve+65Ry+++KIOHjyo+vXra9WqVVqyZImGDRtmMzDxWh544AGFhIRo4cKFatu2rcLDw+163ahRo7Rw4ULdfffd6t+/v2rXrq0///xTs2bN0rFjx2wCxg8//KDBgwfr0UcfVc2aNZWTk6P//Oc/cnd3V6dOnSRJbdq0kaenp9q3b6/+/fsrIyND06ZNU3h4uE3wK1++vJ555hlNnDhRHTp00P3336+dO3dq+fLlCg0NtRk/NHLkSH311Vd68MEH1atXL912223KzMzUzz//rEWLFungwYNXPZU4cuRI/frrr5o4caKSk5PVuXNnRURE6Pjx4/ryyy+1ZcsWbdy40fp5zJ8/X23bttXQoUMVHBys2bNnKyUlRZ9//nmhExhej9jYWMXHx9tcnixJCQkJ1j4PPvig/vOf/yggIEB16tTRpk2b9N13313XJb+zZ8/WlClT1LFjR1WvXl3nzp3TtGnT5O/vr3bt2kly7vcTpYwrLjUCirJv3z5jwIABRkxMjOHt7W34+PgYtWvXNp5++mljx44dNn2vddnxlebMmWPccccdRtmyZQ0vLy+jdu3aRkJCgs1lw1eTf3ny1RR2ebJhGMb+/fuNJ5980oiIiDDKlCljVKpUyXjwwQeNRYsWXfO1Rb3Pnj17GmXLlrVpO3funDF8+HCjYsWKRpkyZYwaNWoYb775ZoHLinWVy4jzDRw40JBkzJs376r9rnTkyBHjqaeeMipVqmR4eHgYwcHBxoMPPmhs3rzZpt+BAweMPn36GNWrVze8vb2N4OBg45577jG+++47m35fffWVUa9ePcPb29uIjo42JkyYYHz88cc2l8caxt+XbL/00ktGRESE4ePjY9x7773Gb7/9ZoSEhNhc2p3/OY0ePdqIiYkxPD09jdDQUKNZs2bGW2+9ZXN58NUsWrTIaNOmjREcHGx4eHgYFSpUMB577DFj9erVNv32799vdO7c2QgMDDS8vb2Nxo0bG8uWLbPpk3958pWXajvyncj/mc6ZM8eoUaOG4eXlZTRs2NB6OXi+s2fPGr179zZCQ0MNPz8/Iz4+3ti9e7cRFRVlcxl3Udu+fFn+5//jjz8a3bp1M6pUqWJ4eXkZ4eHhxoMPPmhzqbRhXP/388oaUTpYDIORSQAKGj58uGbMmKHjx4+X2KXeJS01NVVBQUEaP368XnzxRVeXU6IsFosGDRpU6Oku4EbGGBUABVy4cEFz5sxRp06dbpiQUtjVRvmDgO25OzYAc2KMCgCrEydO6LvvvtOiRYt0+vRpmxsvmt2CBQs0a9YstWvXTn5+flq/fr11DFLz5s1dXR6AYiKoALDatWuXunfvrvDwcL3//vtFXnZtRvXq1ZOHh4feeOMNpaenWwfYjh8/3tWlAbgOjFEBAACmxRgVAABgWgQVAABgWjf0GJW8vDz9+eefKleunFPv6goAAEqOYRg6d+6cKlaseM2JD2/ooPLnn38WuHcLAAC4MRw+fPiaM47f0EEl/8ZWhw8ftt5+HQAAmFt6eroiIyNtblBZlBs6qOSf7vH39yeoAABwg7Fn2AaDaQEAgGkRVAAAgGkRVAAAgGnd0GNUAACAa+Tm5urSpUuFLitTpozc3d2dsh2CCgAAsJthGDp+/LhSU1Ov2i8wMFARERHXPc8ZQQUAANgtP6SEh4fL19e3QBAxDENZWVk6ceKEJKlChQrXtT2CCgAAsEtubq41pISEhBTZz8fHR5J04sQJhYeHX9dpIAbTAgAAu+SPSfH19b1m3/w+RY1jsRdBBQAAOMSecSfOugcfQQUAAJgWQQUAAJgWQQUAAJgWQQUAADjEMAyn9LEHQQUAANilTJkykqSsrKxr9s3vk/+a4mIeFQAAYBd3d3cFBgZaJ3O71oRvgYGB1z2VPkHlapx0aRVwU3LSYV0AN5aIiAhJsoaVouRPoX+9CCoAAMBuFotFFSpUUHh4ODclBAAA5uTu7u60MHI1DKYFAACmRVABAACmRVABAACmRVABAACmRVABAACmRVABAACmRVABAACmRVABAACmRVABAACmRVABAACmRVABAACmRVABAACm5fKgcvToUT3xxBMKCQmRj4+P4uLitG3bNleXBQAATMCld08+e/asmjdvrnvuuUfLly9XWFiY9u7dq6CgIFeWBQAATMKlQWXChAmKjIzUzJkzrW1Vq1Z1YUUAAMBMXHrq56uvvlKjRo306KOPKjw8XA0bNtS0adOK7J+dna309HSbBwAAuHm5NKgcOHBASUlJqlGjhlauXKkBAwZo6NChmj17dqH9ExMTFRAQYH1ERkb+wxUDAIB/ksUwDMNVG/f09FSjRo20ceNGa9vQoUO1detWbdq0qUD/7OxsZWdnW5+np6crMjJSaWlp8vf3d36BFovz1wncLFy36wBwg0tPT1dAQIBdv79dekSlQoUKqlOnjk3bLbfcoj/++KPQ/l5eXvL397d5AACAm5dLg0rz5s21Z88em7bff/9dUVFRLqoIAACYiUuDyvDhw7V582a99tpr2rdvn+bNm6ePPvpIgwYNcmVZAADAJFwaVG6//XZ98cUXmj9/vmJjY/XKK6/o3XffVffu3V1ZFgAAMAmXDqa9Xo4MxikWBtMCRbtxdx0AXOyGGUwLAABwNQQVAABgWgQVAABgWgQVAABgWgQVAABgWgQVAABgWgQVAABgWgQVAABgWgQVAABgWgQVAABgWgQVAABgWgQVAABgWgQVAABgWgQVAABgWgQVAABgWgQVAABgWgQVAABgWgQVAABgWgQVAABgWgQVAABgWgQVAABgWgQVAABgWgQVAABgWgQVAABgWgQVAABgWgQVAABgWgQVAABgWgQVAABgWgQVAABgWgQVAABgWgQVAABgWgQVAABgWgQVAABgWgQVAABgWgQVAABgWgQVAABgWgQVAABgWgQVAABgWgQVAABgWgQVAABgWgQVAABgWgQVAABgWgQVAABgWgQVAABgWi4NKi+//LIsFovNo3bt2q4sCQAAmIiHqwuoW7euvvvuO+tzDw+XlwQAAEzC5anAw8NDERERri4DAACYULFO/Vy6dEmHDx/Wnj17dObMmesqYO/evapYsaKqVaum7t27648//riu9QEAgJuH3UHl3LlzSkpKUosWLeTv76/o6GjdcsstCgsLU1RUlPr166etW7c6tPEmTZpo1qxZWrFihZKSkpSSkqK77rpL586dK7R/dna20tPTbR4AAODmZTEMw7hWp7fffluvvvqqqlevrvbt26tx48aqWLGifHx8dObMGf3yyy9at26dvvzySzVp0kQffPCBatSo4XAxqampioqK0ttvv62+ffsWWP7yyy8rISGhQHtaWpr8/f0d3t41WSzOXydws7j2rgMACpWenq6AgAC7fn/bFVS6deumMWPGqG7dulftl52drZkzZ8rT01N9+vRxrOr/5/bbb1fr1q2VmJhY6Pqzs7Otz9PT0xUZGUlQAVyBoAKgmBwJKnYNpp0/f75dG/by8tLTTz9tV9/CZGRkaP/+/erRo0eR6/fy8ir2+gEAwI3FpfOo/Otf/9KaNWt08OBBbdy4UR07dpS7u7u6devmyrIAAIBJOBRUkpOTNXHiRG3YsEGSNHXqVFWpUkVhYWHq16+fzp8/79DGjxw5om7duqlWrVrq0qWLQkJCtHnzZoWFhTm0HgAAcHOyex6VadOmacCAAapatapefPFFjRs3Tq+++qp69OghNzc3zZkzRyEhIXr99dft3vinn35arKIBAEDpYNdgWkmKjY1V//79NWTIEK1YsULt27fX9OnT1bNnT0nSwoULNXr0aO3bt69EC76cI4NxioXBtEDRGEwLoJgc+f1t96mfAwcOqEOHDpKk+++/XxaLRY0bN7Yub9KkiQ4fPlzMkgEAAAqyO6hcuHBBPj4+1udXXoHj5eWlnJwc51YHAABKNbvHqFgsFp07d07e3t4yDEMWi0UZGRnW2WGZJRYAADib3UHFMAzVrFnT5nnDhg1tnlsY0wEAAJzI7qCSnJxcknUAAAAUYHdQadGiRUnWAQAAUIDdQeVKv/76q3Jzc63P3d3dr3kvIAAAAEfYfdXPunXrdPvtt1uf33HHHWrYsKEaNGigBg0aqF69evruu+9KpEgAAFA62R1UpkyZUuBmgcnJyUpJSdGBAwf0zDPPKCkpyekFAgCA0svuoLJt2zbde++9Nm2VK1dWVFSUoqOj1aNHD23atMnpBQIAgNLL7qBy5MgRBQQEWJ/Pnj1bERER1ufBwcE6ffq0c6sDAAClmt1BpVy5ctq/f7/1+SOPPCJfX1/r85SUlJK53w4AACi17A4qTZo00SeffFLk8lmzZqlJkyZOKQoAAEBy4PLkESNGqHXr1goJCdHIkSMVHh4uSTpx4oQmTJigOXPmaNWqVSVWKAAAKH0shmH/vdqnTJmi4cOHKycnR/7+/rJYLEpLS5OHh4cmTpyowYMHl2StBThym+hi4ZYAQNHs33UAgA1Hfn87FFQk6fDhw1q0aJH27t0rSapRo4Y6d+6syMjI4ldcTAQVwIUIKgCKqUSDipkQVAAXunF3HQBczJHf33YPpgUAAPinEVQAAIBpEVQAAIBpEVQAAIBp2T2PypUuXryoEydOKC8vz6a9SpUq110UAACAVIygsnfvXvXp00cbN260aTcMQxaLRbm5uU4rDgAAlG4OB5VevXrJw8NDy5YtU4UKFWThEl4AAFBCHA4qO3bs0Pbt21W7du2SqAcAAMDK4cG0derU0alTp0qiFgAAABsOB5UJEyboueee0+rVq3X69Gmlp6fbPAAAAJzF4Sn03dz+zjZXjk1xxWBaptAHXIgp9AEUkyO/vx0eo5KcnFzswgAAABzhcFBp0aJFSdQBAABQgF1B5aefflJsbKzc3Nz0008/XbVvvXr1nFIYAACAXUGlQYMGOn78uMLDw9WgQQNZLBYVNrSFCd8AAIAz2RVUUlJSFBYWZv03AADAP8GuoBIVFVXovwEAAEqSXfOobN682e4VZmVl6ddffy12QQAAAPnsCio9evRQfHy8Fi5cqMzMzEL77Nq1Sy+88IKqV6+u7du3O7VIAABQOtl16mfXrl1KSkrSmDFj9Pjjj6tmzZqqWLGivL29dfbsWe3evVsZGRnq2LGjVq1apbi4uJKuGwAAlAIOz0y7bds2rV+/XocOHdL58+cVGhqqhg0b6p577lFwcHBJ1VkoZqYFXIiZaQEUU4nOTNuoUSM1atSo2MUBAADYy+GbEgIAAPxTCCoAAMC0CCoAAMC0CCoAAMC0riuoXLhwwVl1AAAAFOBwUMnLy9Mrr7yiSpUqyc/PTwcOHJAkvfTSS5oxY0axC3n99ddlsVg0bNiwYq8DAADcXBwOKuPHj9esWbP0xhtvyNPT09oeGxur6dOnF6uIrVu3aurUqapXr16xXg8AAG5ODgeVTz75RB999JG6d+8ud3d3a3v9+vW1e/duhwvIyMhQ9+7dNW3aNAUFBTn8egAAcPNyOKgcPXpUMTExBdrz8vJ06dIlhwsYNGiQHnjgAbVu3fqafbOzs5Wenm7zAAAANy+Hg0qdOnW0bt26Au2LFi1Sw4YNHVrXp59+qh9//FGJiYl29U9MTFRAQID1ERkZ6dD2AADAjcXhKfTHjh2rnj176ujRo8rLy9PixYu1Z88effLJJ1q2bJnd6zl8+LCeeeYZffvtt/L29rbrNaNHj9aIESOsz9PT0wkrAADcxBy+KaEkrVu3Tv/+97+1c+dOZWRk6NZbb9XYsWPVpk0bu9fx5ZdfqmPHjjbjXHJzc2WxWOTm5qbs7GybZYXhpoSAC3FTQgDF5Mjv72IFFWc4d+6cDh06ZNPWu3dv1a5dW88//7xiY2OvuQ6CCuBCBBUAxVSid092lnLlyhUII2XLllVISIhdIQUAANz8HA4qQUFBshRypMFiscjb21sxMTHq1auXevfu7ZQCAQBA6VWswbSvvvqq2rZtq8aNG0uStmzZohUrVmjQoEFKSUnRgAEDlJOTo379+jm07tWrVztaDgAAuIk5HFTWr1+v8ePH6+mnn7Zpnzp1qlatWqXPP/9c9erV0/vvv+9wUAEAALicw/OorFy5stDJ2Vq1aqWVK1dKktq1a2e9BxAAAEBxORxUgoODtXTp0gLtS5cuVXBwsCQpMzNT5cqVu/7qAABAqebwqZ+XXnpJAwYMUHJysnWMytatW/XNN9/oww8/lCR9++23atGihXMrBQAApU6x5lHZsGGDJk2apD179kiSatWqpSFDhqhZs2ZOL/BqmEcFcCHmUQFQTCU+j0rz5s3VvHnzYhUHAABgr+ua8O3ChQu6ePGiTVuJHNkAAAClksODabOysjR48GCFh4erbNmyCgoKsnkAAAA4i8NBZeTIkfrhhx+UlJQkLy8vTZ8+XQkJCapYsaI++eSTkqgRAACUUg6f+lm6dKk++eQTtWzZUr1799Zdd92lmJgYRUVFae7cuerevXtJ1AkAAEohh4+onDlzRtWqVZP093iUM2fOSJLuvPNOrV271rnVAQCAUs3hoFKtWjWlpKRIkmrXrq3PPvtM0t9HWgIDA51aHAAAKN0cDiq9e/fWzp07JUmjRo3S5MmT5e3treHDh2vkyJFOLxAAAJRexZrw7XKHDh3S9u3bFRMTo3r16jmrLrsw4RvgQkz4BqCYSnzCt8tFRUUpICCA0z4AAMDpHD71M2HCBC1YsMD6vEuXLgoJCVGlSpWsp4QAAACcweGg8uGHHyoyMlLS3zcf/Pbbb7V8+XK1bduWMSoAAMCpHD71c/z4cWtQWbZsmbp06aI2bdooOjpaTZo0cXqBAACg9HL4iEpQUJAOHz4sSVqxYoVat24tSTIMQ7m5uc6tDgAAlGoOH1F55JFH9Pjjj6tGjRo6ffq02rZtK0n63//+p5iYGKcXCAAASi+Hg8o777yj6OhoHT58WG+88Yb8/PwkSceOHdPAgQOdXiAAACi9rnseFVdiHhXAhW7cXQcAFyuReVTef//9QtsDAgJUs2ZNNW3a1LEqAQAArsHuoPLOO+8U2p6amqq0tDQ1a9ZMX331lYKDg51WHACUNA6cAlfn6oOndl/1k5KSUujj7Nmz2rdvn/Ly8jRmzJiSrBUAAJQyDl+eXJhq1arp9ddf16pVq5yxOgAAAElOCiqSVKVKFR0/ftxZqwMAAHBeUPn5558VFRXlrNUBAADYP5g2PT290Pa0tDRt375dzz77rHr27Om0wgAAAOwOKoGBgbIUMTzeYrHoqaee0qhRo5xWGAAAgN1BJTk5udB2f39/1ahRwzpDLQAAgLPYHVRatGhRknUAAAAU4LTBtAAAAM5GUAEAAKZFUAEAAKZFUAEAAKblcFAZN26cDh06VBK1AAAA2HA4qCxZskTVq1dXq1atNG/ePGVnZ5dEXQAAAI4HlR07dmjr1q2qW7eunnnmGUVERGjAgAHaunVrSdQHAABKsWKNUWnYsKHef/99/fnnn5oxY4aOHDmi5s2bq169enrvvfeUlpbm7DoBAEApdF2DaQ3D0KVLl3Tx4kUZhqGgoCBNmjRJkZGRWrBggbNqBAAApVSxgsr27ds1ePBgVahQQcOHD1fDhg3122+/ac2aNdq7d69effVVDR061Nm1AgCAUsZiGIbhyAvi4uK0e/dutWnTRv369VP79u3l7u5u0+fUqVMKDw9XXl6eU4u9Unp6ugICApSWliZ/f3/nb6CImzACkOTYrsO0+G8OXF1J/Fd35Pe33ff6ydelSxf16dNHlSpVKrJPaGhoiYcUAABw83Po1M+lS5c0a9YspaenO2XjSUlJqlevnvz9/eXv76+mTZtq+fLlTlk3AAC48TkUVMqUKaMLFy44beOVK1fW66+/ru3bt2vbtm2699579dBDD+nXX3912jYAAMCNy+ExKq+99pp+//13TZ8+XR4eDp85uqbg4GC9+eab6tu37zX7MkYFcCHGqAClwg03RmXr1q36/vvvtWrVKsXFxals2bI2yxcvXuzoKiVJubm5WrhwoTIzM9W0adNC+2RnZ9vMhOusU1AAAMCcHA4qgYGB6tSpk9MK+Pnnn9W0aVNduHBBfn5++uKLL1SnTp1C+yYmJiohIcFp2wYAAObm8KkfZ7t48aL++OMPpaWladGiRZo+fbrWrFlTaFgp7IhKZGQkp34AV+DUD1AquPrUT7GDysmTJ7Vnzx5JUq1atRQWFlac1RTQunVrVa9eXVOnTr1mX8aoAC5EUAFKBVcHFYdnps3MzFSfPn1UoUIF3X333br77rtVsWJF9e3bV1lZWcUuOl9eXh53ZAYAAJKKEVRGjBihNWvWaOnSpUpNTVVqaqqWLFmiNWvW6Nlnn3VoXaNHj9batWt18OBB/fzzzxo9erRWr16t7t27O1oWAAC4CTk8mPbzzz/XokWL1LJlS2tbu3bt5OPjoy5duigpKcnudZ04cUJPPvmkjh07poCAANWrV08rV67Ufffd52hZAADgJuRwUMnKylL58uULtIeHhzt86mfGjBmObh4AAJQiDp/6adq0qcaNG2czQ+358+eVkJBQ5PwnAAAAxeHwEZX33ntP8fHxqly5surXry9J2rlzp7y9vbVy5UqnFwgAAEovh4NKbGys9u7dq7lz52r37t2SpG7duql79+7y8fFxeoEAAKD0KtbNenx9fdWvXz9n1wIAAGCjWEHlzz//1Pr163XixAnl5eXZLBs6dKhTCgMAAHA4qMyaNUv9+/eXp6enQkJCZLlsWkeLxUJQAQAATuNwUHnppZc0duxYjR49Wm5uDl80BAAAYDeHk0ZWVpa6du1KSAEAACXO4bTRt29fLVy4sCRqAQAAsOHw3ZNzc3P14IMP6vz584qLi1OZMmVslr/99ttOLfBquHsy4ELcPRkoFVx992SHx6gkJiZq5cqVqlWrliQVGEwLAADgLA4HlYkTJ+rjjz9Wr169SqAcAACA/5/DY1S8vLzUvHnzkqgFAADAhsNB5ZlnntEHH3xQErUAAADYcPjUz5YtW/TDDz9o2bJlqlu3boHBtIsXL3ZacQAAoHRzOKgEBgbqkUceKYlaAAAAbDgcVGbOnFkSdQAAABRQrOllc3Jy9N1332nq1Kk6d+6cpL9vVJiRkeHU4gAAQOnm8BGVQ4cO6f7779cff/yh7Oxs3XfffSpXrpwmTJig7OxsffjhhyVRJwAAKIWKddVPo0aNdPbsWfn4+FjbO3bsqO+//96pxQEAgNLN4SMq69at08aNG+Xp6WnTHh0draNHjzqtMAAAAIePqOTl5Sk3N7dA+5EjR1SuXDmnFAUAACAVI6i0adNG7777rvW5xWJRRkaGxo0bp3bt2jmzNgAAUMo5fPfkI0eOKD4+XoZhaO/evWrUqJH27t2r0NBQrV27VuHh4SVVawHcPRlwIe6eDJQKrr57ssNBRfr78uRPP/1UP/30kzIyMnTrrbeqe/fuNoNr/wkEFcCFCCpAqeDqoOLwYFpJ8vDw0BNPPFGs4gAAAOxld1BZu3atXf3uvvvuYhcDAABwObuDSsuWLWX5f8dIizpbZLFYCr0iCAAAoDjsDipBQUEqV66cevXqpR49eig0NLQk6wIAALD/8uRjx45pwoQJ2rRpk+Li4tS3b19t3LhR/v7+CggIsD4AAACcxe6g4unpqccee0wrV67U7t27Va9ePQ0ePFiRkZF68cUXlZOTU5J1AgCAUqhYlyfnS0lJUd++fbVmzRqdPHlSwcHBzqztmrg8GXAhLk8GSgVXX57s8My02dnZmjdvnlq3bq3Y2FiFhobq66+//sdDCgAAuPnZPZh2y5Ytmjlzpj799FNFR0erd+/e+uyzzwgoAACgxNh96sfNzU1VqlRRz549ddtttxXZr0OHDk4r7lo49QO4EKd+gFLB1ad+HAoq1/JPz6NCUAFciKAClAquDip2n/rJy8u77sIAAAAc4fBgWgAAgH8KQQUAAJgWQQUAAJgWQQUAAJgWQQUAAJiW3Vf9pKenF9petmxZubu7O60gAACAfHYfUQkMDFRQUFCBh4+Pj2rVqqVp06aVZJ0AAKAUsvuISnJycqHtqamp2r59u0aOHCkPDw/17t3bacUBAIDS7brunny5jz/+WJMmTdKPP/5o92sSExO1ePFi7d69Wz4+PmrWrJkmTJigWrVq2fV6ZqYFXIiZaYFSwdUz0zptMG2LFi20b98+h16zZs0aDRo0SJs3b9a3336rS5cuqU2bNsrMzHRWWQAA4AZm96mfa0lLS1NAQIBDr1mxYoXN81mzZik8PFzbt2/X3Xff7azSAADADcopQeXSpUt688031aRJk+taT1pamiQpODi40OXZ2dnKzs62Pi/qSiQAAHBzsDuoPPLII4W2p6Wl6ddff5XFYtG6deuKXUheXp6GDRum5s2bKzY2ttA+iYmJSkhIKPY2AADAjcXuwbRFXc3j7++vWrVqqXv37g6f+rncgAEDtHz5cq1fv16VK1cutE9hR1QiIyMZTAu4AoNpgVLB1YNp7T6iMnPmzOsurCiDBw/WsmXLtHbt2iJDiiR5eXnJy8urxOoAAADm4tAYlc2bN2vp0qW6ePGiWrVqpfvvv/+6Nm4YhoYMGaIvvvhCq1evVtWqVa9rfQAA4OZid1BZtGiRHnvsMfn4+KhMmTJ6++23NWHCBP3rX/8q9sYHDRqkefPmacmSJSpXrpyOHz8uSQoICJCPj0+x1wsAAG4Odo9Rue2223T77bdr8uTJcnd3V2Jiot58802dOXOm+Bsv4uTwzJkz1atXr2u+ngnfABdijApQKrh6jIrdQcXPz087duxQTEyMJOnixYsqW7asjh49qvDw8OuvuhgIKoALEVSAUsHVQcXumWmzsrJsVubp6Slvb29lZGQUv1IAAICrcGgw7fTp0+Xn52d9npOTo1mzZik0NNTaNnToUOdVBwAASjW7T/1ER0cXOabEujKLRQcOHHBKYfbg1A/gQpz6AUoFV5/6sfuIysGDB6+3LgAAAIc47e7JAAAAzmb3EZXz58/r+++/14MPPihJGj16tM109u7u7nrllVfk7e3t/CoBAECpZHdQmT17tr7++mtrUJk0aZLq1q1rnZht9+7dqlixooYPH14ylQIAgFLH7lM/c+fO1f/93//ZtM2bN0/JyclKTk7Wm2++qc8++8zpBQIAgNLL7qCyb98+xcXFWZ97e3vLze3/f3njxo21a9cu51YHAABKNbtP/aSmptqMSTl58qTN8ry8PJvlAAAA18vuIyqVK1fWL7/8UuTyn376SZUrV3ZKUQAAAJIDQaVdu3YaO3asLly4UGDZ+fPnlZCQoAceeMCpxQEAgNLN7plp//rrLzVo0ECenp4aPHiwatasKUnas2ePJk2apJycHP3vf/9T+fLlS7TgyzEzLeBCzEwLlAo3zMy05cuX18aNGzVgwACNGjVK+fnGYrHovvvu05QpU/7RkAIAAG5+Dt2UsGrVqlqxYoXOnDmjffv2SZJiYmIUHBxcIsUBAIDSzaGgki84OFiNGzd2di0AAAA2uNcPAAAwLYIKAAAwLYIKAAAwLYIKAAAwLYIKAAAwLYIKAAAwLYIKAAAwLYIKAAAwLYIKAAAwLYIKAAAwLYIKAAAwLYIKAAAwLYIKAAAwLYIKAAAwLYIKAAAwLYIKAAAwLYIKAAAwLYIKAAAwLYIKAAAwLYIKAAAwLYIKAAAwLYIKAAAwLYIKAAAwLYIKAAAwLYIKAAAwLYIKAAAwLYIKAAAwLYIKAAAwLZcGlbVr16p9+/aqWLGiLBaLvvzyS1eWAwAATMalQSUzM1P169fX5MmTXVkGAAAwKQ9Xbrxt27Zq27atK0sAAAAm5tKg4qjs7GxlZ2dbn6enp7uwGgAAUNJuqMG0iYmJCggIsD4iIyNdXRIAAChBN1RQGT16tNLS0qyPw4cPu7okAABQgm6oUz9eXl7y8vJydRkAAOAfckMdUQEAAKWLS4+oZGRkaN++fdbnKSkp2rFjh4KDg1WlShUXVgYAAMzApUFl27Ztuueee6zPR4wYIUnq2bOnZs2a5aKqAACAWbg0qLRs2VKGYbiyBAAAYGKMUQEAAKZFUAEAAKZFUAEAAKZFUAEAAKZFUAEAAKZFUAEAAKZFUAEAAKZFUAEAAKZFUAEAAKZFUAEAAKZFUAEAAKZFUAEAAKZFUAEAAKZFUAEAAKZFUAEAAKZFUAEAAKZFUAEAAKZFUAEAAKZFUAEAAKZFUAEAAKZFUAEAAKZFUAEAAKZFUAEAAKZFUAEAAKZFUAEAAKZFUAEAAKZFUAEAAKZFUAEAAKZFUAEAAKZFUAEAAKZFUAEAAKZFUAEAAKZFUAEAAKZFUAEAAKZFUAEAAKZFUAEAAKZFUAEAAKZFUAEAAKZFUAEAAKZFUAEAAKZFUAEAAKZFUAEAAKZFUAEAAKZFUAEAAKZliqAyefJkRUdHy9vbW02aNNGWLVtcXRIAADABlweVBQsWaMSIERo3bpx+/PFH1a9fX/Hx8Tpx4oSrSwMAAC7m8qDy9ttvq1+/furdu7fq1KmjDz/8UL6+vvr4449dXRoAAHAxlwaVixcvavv27WrdurW1zc3NTa1bt9amTZtcWBkAADADD1du/NSpU8rNzVX58uVt2suXL6/du3cX6J+dna3s7Gzr87S0NElSenp6yRYKoCD+3wGlQkn8V8//vW0YxjX7ujSoOCoxMVEJCQkF2iMjI11QDVDKBQS4ugIA/4CS/K9+7tw5BVxjAy4NKqGhoXJ3d9dff/1l0/7XX38pIiKiQP/Ro0drxIgR1ud5eXk6c+aMQkJCZLFYSrxeuE56eroiIyN1+PBh+fv7u7ocACWA/+elh2EYOnfunCpWrHjNvi4NKp6enrrtttv0/fff6+GHH5b0d/j4/vvvNXjw4AL9vby85OXlZdMWGBj4D1QKs/D392cHBtzk+H9eOlzrSEo+l5/6GTFihHr27KlGjRqpcePGevfdd5WZmanevXu7ujQAAOBiLg8qjz32mE6ePKmxY8fq+PHjatCggVasWFFggC0AACh9XB5UJGnw4MGFnuoB8nl5eWncuHEFTv0BuHnw/xyFsRj2XBsEAADgAi6fmRYAAKAoBBUAAGBaBBUAAGBaBBUAAGBaBBX8I44fP65nnnlGMTEx8vb2Vvny5dW8eXMlJSUpKytLkhQdHS2LxSKLxaKyZcvq1ltv1cKFCwssK+zRq1evAttcvHix7rvvPoWFhcnf319NmzbVypUr/8m3DZhWr169rBNtFvf1+f//ypQpo6pVq+q5557ThQsXCvQ9cuSIPD09FRsba/f67dlnSOw3SgNTXJ6Mm9uBAwfUvHlzBQYG6rXXXlNcXJy8vLz0888/66OPPlKlSpXUoUMHSdK///1v9evXT+np6Zo4caIee+wxVapUSVu3blVubq4kaePGjerUqZP27Nljnb3Sx8enwHbXrl2r++67T6+99poCAwM1c+ZMtW/fXv/973/VsGHDf+4DAG5S999/v2bOnKlLly5p+/bt6tmzpywWiyZMmGDTb9asWerSpYvWrl2r//73v2rSpMlV1+vIPkNiv3HTM4ASFh8fb1SuXNnIyMgodHleXp5hGIYRFRVlvPPOO9b2S5cuGb6+vsaoUaNs+icnJxuSjLNnzzpcS506dYyEhASHXwfcbHr27Gk89NBDRS5fvXq1cfvttxuenp5GRESE8fzzzxuXLl266usfeeQRo2HDhjZteXl5RrVq1YwVK1YYzz//vNGvX79r1mbvPsMw2G+UBpz6QYk6ffq0Vq1apUGDBqls2bKF9inqhpIeHh4qU6aMLl686JRa8vLydO7cOQUHBztlfcDN6ujRo2rXrp1uv/127dy5U0lJSZoxY4bGjx9f5Gt++eUXbdy4UZ6enjbtycnJysrKUuvWrfXEE0/o008/VWZmZpHruZ59hsR+42ZEUEGJ2rdvnwzDUK1atWzaQ0ND5efnJz8/Pz3//PMFXnfx4kUlJiYqLS1N9957r1Nqeeutt5SRkaEuXbo4ZX3AzWrKlCmKjIzUpEmTVLt2bT388MNKSEjQxIkTlZeXZ+23bNky+fn5ydvbW3FxcTpx4oRGjhxps64ZM2aoa9eucnd3V2xsrKpVq2YdQ1KY4u4zJPYbNyuCClxiy5Yt2rFjh+rWravs7Gxr+/PPPy8/Pz/5+vpqwoQJev311/XAAw9cc335OzA/Pz89/fTTBZbPmzdPCQkJ+uyzzxQeHu7U9wLcbH777Tc1bdrU5shF8+bNlZGRoSNHjljb7rnnHu3YsUP//e9/1bNnT/Xu3VudOnWyLk9NTdXixYv1xBNPWNueeOIJzZgxw+GaitpnSOw3bnYMpkWJiomJkcVi0Z49e2zaq1WrJqngYLaRI0eqV69e8vPzU/ny5a96iPdyO3bssP77ytvDf/rpp3rqqae0cOFCtW7duhjvAkBhypYtq5iYGEnSxx9/rPr162vGjBnq27evpL9/0V+4cMFm8KxhGMrLy9Pvv/+umjVrFlino/sMif3GzY4jKihRISEhuu+++zRp0qSrnpfOFxoaqpiYGEVERNi9s5H+3rnlPy7/y2f+/Pnq3bu35s+fb9dfWACkW265RZs2bZJx2a3gNmzYoHLlyqly5cqFvsbNzU0vvPCCxowZo/Pnz0v6+7TPs88+qx07dlgfO3fu1F133aWPP/640PU4us+Q2G/c7AgqKHFTpkxRTk6OGjVqpAULFui3337Tnj17NGfOHO3evVvu7u4lst158+bpySef1MSJE9WkSRMdP35cx48fV1paWolsD7jRpKWl2YSIHTt26PDhwxo4cKAOHz6sIUOGaPfu3VqyZInGjRunESNGyM2t6F8bjz76qNzd3TV58mTt2LFDP/74o5566inFxsbaPLp166bZs2crJyen0PW4ap8hsd8wJddedITS4s8//zQGDx5sVK1a1ShTpozh5+dnNG7c2HjzzTeNzMxMwzAKXmZYFHsvM2zRooUhqcCjZ8+e1/+GgBtcz549C/3/0bdvX8Mwind5smEYRmJiohEWFmY89dRTRp06dQrd9rFjxww3NzdjyZIlRdZnzz7DMNhvlAYWw7js2B4AAICJcOoHAACYFkEFAACYFkEFAACYFkEFAACYFkEFAACYFkEFAACYFkEFAACYFkEFgMv06tVLDz/8sKvLAGBi3JQQQIm41j1Xxo0bp/fee0/MOQngaggqAErEsWPHrP9esGCBxo4da3NHXD8/P/n5+bmiNAA3EE79ACgRERER1kdAQIAsFotNm5+fX4FTPy1bttSQIUM0bNgwBQUFqXz58po2bZoyMzPVu3dvlStXTjExMVq+fLnNtn755Re1bdtWfn5+Kl++vHr06KFTp079w+8YQEkgqAAwldmzZys0NFRbtmzRkCFDNGDAAD366KNq1qyZfvzxR7Vp00Y9evRQVlaWJCk1NVX33nuvGjZsqG3btmnFihX666+/1KVLFxe/EwDOQFABYCr169fXmDFjVKNGDY0ePVre3t4KDQ1Vv379VKNGDY0dO1anT5/WTz/9JEmaNGmSGjZsqNdee021a9dWw4YN9fHHHys5OVm///67i98NgOvFGBUAplKvXj3rv93d3RUSEqK4uDhrW/ny5SVJJ06ckCTt3LlTycnJhY532b9/v2rWrFnCFQMoSQQVAKZSpkwZm+cWi8WmLf9qory8PElSRkaG2rdvrwkTJhRYV4UKFUqwUgD/BIIKgBvarbfeqs8//1zR0dHy8GCXBtxsGKMC4IY2aNAgnTlzRt26ddPWrVu1f/9+rVy5Ur1791Zubq6rywNwnQgqAG5oFStW1IYNG5Sbm6s2bdooLi5Ow4YNU2BgoNzc2MUBNzqLwbSQAADApPhzAwAAmBZBBQAAmBZBBQAAmBZBBQAAmBZBBQAAmBZBBQAAmBZBBQAAmBZBBQAAmBZBBQAAmBZBBQAAmBZBBQAAmBZBBQAAmNb/B+AR+hVFKhpsAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.bar(\n",
    "    [\"GPT-2\", \"LoRA GPT-2\"],\n",
    "    [max(gpt2_lm_memory_usage), max(lora_model_memory_usage)],\n",
    "    color=[\"red\", \"blue\"],\n",
    ")\n",
    "\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"GPU Memory Usage (in GB)\")\n",
    "\n",
    "plt.title(\"GPU Memory Usage Comparison\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5030d1e9-96d3-4461-86b5-85fb782250aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer_idx in range(lora_model.backbone.num_layers):\n",
    "    self_attention_layer = lora_model.backbone.get_layer(\n",
    "        f\"transformer_layer_{layer_idx}\"\n",
    "    )._self_attention_layer\n",
    "\n",
    "    # Merge query dense layer.\n",
    "    query_lora_layer = self_attention_layer._query_dense\n",
    "\n",
    "    A_weights = query_lora_layer.A.kernel  # (768, 1) (a, b)\n",
    "    B_weights = query_lora_layer.B.kernel  # (1, 12, 64) (b, c, d)\n",
    "    increment_weights = tf.einsum(\"ab,bcd->acd\", A_weights, B_weights) * (ALPHA / RANK)\n",
    "    query_lora_layer.original_layer.kernel.assign_add(increment_weights)\n",
    "\n",
    "    # Merge value dense layer.\n",
    "    value_lora_layer = self_attention_layer._value_dense\n",
    "\n",
    "    A_weights = value_lora_layer.A.kernel  # (768, 1) (a, b)\n",
    "    B_weights = value_lora_layer.B.kernel  # (1, 12, 64) (b, c, d)\n",
    "    increment_weights = tf.einsum(\"ab,bcd->acd\", A_weights, B_weights) * (ALPHA / RANK)\n",
    "    value_lora_layer.original_layer.kernel.assign_add(increment_weights)\n",
    "\n",
    "    # Put back in place the original layers with updated weights\n",
    "    self_attention_layer._query_dense = query_lora_layer.original_layer\n",
    "    self_attention_layer._value_dense = value_lora_layer.original_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ed309f5a-8022-4f10-b4be-cb6ef6c7baad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Output:\n",
      "I like basketball, so I decided to try to make some basketball fun. I was playing basketball at the school gym when I saw a group of guys with basketball caps on their heads and I thought, \"hey, what are these guys doing?\" I didn't know they were basketball players, but I was so nervous. So I asked my coach what was wrong, and he said, \"it's basketball.\"\n",
      "The basketball was so fun.\n",
      "My mom had a really bad night and I was so nervous. I didn't know why she was so nervous.\n",
      "I was really scared. My mom said, \"you know what, you know what, you can do something stupid, you know what, I'll do something stupid, and you'll be so happy.\"\n",
      "So I went out with her and we had a basketball game.\n",
      "Total Time Elapsed: 6.35s\n",
      "\n",
      "Output:\n",
      "That Italian restaurant is called \"Casa\" and is located at the corner of the old Italian street and the old street, so you can see the main street. The menu is pretty much identical to what it used to be and there are a ton of different things. I have a couple of different types of dishes, and one is pasta, the other is cheese, and there is a lot of cheese on the menu. The menu has a very good menu and the service is good. The menu is very good and the staff is very friendly and attentive.\n",
      "Total Time Elapsed: 0.78s\n"
     ]
    }
   ],
   "source": [
    "# Freezing weights not necessary during generation since no weights are updated.\n",
    "generate_text(lora_model, \"I like basketball\", max_length=MAX_GENERATION_LENGTH)\n",
    "generate_text(\n",
    "    lora_model, \"That Italian restaurant is\", max_length=MAX_GENERATION_LENGTH\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc822ce7-8ad2-44b0-b392-992303c695ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecdac8e4-1afd-4a9f-9965-4841a53cd884",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aab4478a-94d1-413d-9364-d3d77220a40b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d518bfc7-0bcc-48f8-8c6a-f73d0c0cc780",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4062ea1f-1990-4356-b2cf-40cc2a562bb0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe08198c-5a61-49eb-a417-8571eb7edd35",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0d182d6-5598-4819-9756-693ec0b099e9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
