{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "03b1a8a5-82d9-4c72-a87b-5b0a349a166d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-04 13:56:42.351531: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1762261002.363132   14311 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1762261002.366654   14311 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1762261002.376892   14311 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1762261002.376903   14311 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1762261002.376905   14311 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1762261002.376906   14311 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-11-04 13:56:42.380167: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras import layers\n",
    "import numpy as np\n",
    "\n",
    "# Parameters for the model and dataset.\n",
    "TRAINING_SIZE = 50000\n",
    "DIGITS = 3\n",
    "REVERSE = True\n",
    "\n",
    "# Maximum length of input is 'int + int' (e.g., '345+678'). Maximum length of\n",
    "# int is DIGITS.\n",
    "MAXLEN = DIGITS + 1 + DIGITS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e09fd30c-4cf7-4815-92bc-30865cd1fc7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating data...\n",
      "Total questions: 50000\n"
     ]
    }
   ],
   "source": [
    "class CharacterTable:\n",
    "    \"\"\"Given a set of characters:\n",
    "    + Encode them to a one-hot integer representation\n",
    "    + Decode the one-hot or integer representation to their character output\n",
    "    + Decode a vector of probabilities to their character output\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, chars):\n",
    "        \"\"\"Initialize character table.\n",
    "        # Arguments\n",
    "            chars: Characters that can appear in the input.\n",
    "        \"\"\"\n",
    "        self.chars = sorted(set(chars))\n",
    "        self.char_indices = dict((c, i) for i, c in enumerate(self.chars))\n",
    "        self.indices_char = dict((i, c) for i, c in enumerate(self.chars))\n",
    "\n",
    "    def encode(self, C, num_rows):\n",
    "        \"\"\"One-hot encode given string C.\n",
    "        # Arguments\n",
    "            C: string, to be encoded.\n",
    "            num_rows: Number of rows in the returned one-hot encoding. This is\n",
    "                used to keep the # of rows for each data the same.\n",
    "        \"\"\"\n",
    "        x = np.zeros((num_rows, len(self.chars)))\n",
    "        for i, c in enumerate(C):\n",
    "            x[i, self.char_indices[c]] = 1\n",
    "        return x\n",
    "\n",
    "    def decode(self, x, calc_argmax=True):\n",
    "        \"\"\"Decode the given vector or 2D array to their character output.\n",
    "        # Arguments\n",
    "            x: A vector or a 2D array of probabilities or one-hot representations;\n",
    "                or a vector of character indices (used with `calc_argmax=False`).\n",
    "            calc_argmax: Whether to find the character index with maximum\n",
    "                probability, defaults to `True`.\n",
    "        \"\"\"\n",
    "        if calc_argmax:\n",
    "            x = x.argmax(axis=-1)\n",
    "        return \"\".join(self.indices_char[x] for x in x)\n",
    "\n",
    "\n",
    "# All the numbers, plus sign and space for padding.\n",
    "chars = \"0123456789+ \"\n",
    "ctable = CharacterTable(chars)\n",
    "\n",
    "questions = []\n",
    "expected = []\n",
    "seen = set()\n",
    "print(\"Generating data...\")\n",
    "while len(questions) < TRAINING_SIZE:\n",
    "    f = lambda: int(\n",
    "        \"\".join(\n",
    "            np.random.choice(list(\"0123456789\"))\n",
    "            for i in range(np.random.randint(1, DIGITS + 1))\n",
    "        )\n",
    "    )\n",
    "    a, b = f(), f()\n",
    "    # Skip any addition questions we've already seen\n",
    "    # Also skip any such that x+Y == Y+x (hence the sorting).\n",
    "    key = tuple(sorted((a, b)))\n",
    "    if key in seen:\n",
    "        continue\n",
    "    seen.add(key)\n",
    "    # Pad the data with spaces such that it is always MAXLEN.\n",
    "    q = \"{}+{}\".format(a, b)\n",
    "    query = q + \" \" * (MAXLEN - len(q))\n",
    "    ans = str(a + b)\n",
    "    # Answers can be of maximum size DIGITS + 1.\n",
    "    ans += \" \" * (DIGITS + 1 - len(ans))\n",
    "    if REVERSE:\n",
    "        # Reverse the query, e.g., '12+345  ' becomes '  543+21'. (Note the\n",
    "        # space used for padding.)\n",
    "        query = query[::-1]\n",
    "    questions.append(query)\n",
    "    expected.append(ans)\n",
    "print(\"Total questions:\", len(questions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4464a392-3dc1-4fe2-b6f4-c178456c2a0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorization...\n",
      "Training Data:\n",
      "(45000, 7, 12)\n",
      "(45000, 4, 12)\n",
      "Validation Data:\n",
      "(5000, 7, 12)\n",
      "(5000, 4, 12)\n"
     ]
    }
   ],
   "source": [
    "print(\"Vectorization...\")\n",
    "x = np.zeros((len(questions), MAXLEN, len(chars)), dtype=bool)\n",
    "y = np.zeros((len(questions), DIGITS + 1, len(chars)), dtype=bool)\n",
    "for i, sentence in enumerate(questions):\n",
    "    x[i] = ctable.encode(sentence, MAXLEN)\n",
    "for i, sentence in enumerate(expected):\n",
    "    y[i] = ctable.encode(sentence, DIGITS + 1)\n",
    "\n",
    "# Shuffle (x, y) in unison as the later parts of x will almost all be larger\n",
    "# digits.\n",
    "indices = np.arange(len(y))\n",
    "np.random.shuffle(indices)\n",
    "x = x[indices]\n",
    "y = y[indices]\n",
    "\n",
    "# Explicitly set apart 10% for validation data that we never train over.\n",
    "split_at = len(x) - len(x) // 10\n",
    "(x_train, x_val) = x[:split_at], x[split_at:]\n",
    "(y_train, y_val) = y[:split_at], y[split_at:]\n",
    "\n",
    "print(\"Training Data:\")\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "\n",
    "print(\"Validation Data:\")\n",
    "print(x_val.shape)\n",
    "print(y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c146cd5b-c0f7-4bbd-b13e-e452c522445f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1762261053.411007   14311 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 8748 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2080 Ti, pci bus id: 0000:08:00.0, compute capability: 7.5\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">72,192</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ repeat_vector (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">RepeatVector</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │       <span style=\"color: #00af00; text-decoration-color: #00af00\">131,584</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>)          │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,548</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m72,192\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ repeat_vector (\u001b[38;5;33mRepeatVector\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │       \u001b[38;5;34m131,584\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m12\u001b[0m)          │         \u001b[38;5;34m1,548\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">205,324</span> (802.05 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m205,324\u001b[0m (802.05 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">205,324</span> (802.05 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m205,324\u001b[0m (802.05 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Build model...\")\n",
    "num_layers = 1  # Try to add more LSTM layers!\n",
    "\n",
    "model = keras.Sequential()\n",
    "# \"Encode\" the input sequence using a LSTM, producing an output of size 128.\n",
    "# Note: In a situation where your input sequences have a variable length,\n",
    "# use input_shape=(None, num_feature).\n",
    "model.add(layers.Input((MAXLEN, len(chars))))\n",
    "model.add(layers.LSTM(128))\n",
    "# As the decoder RNN's input, repeatedly provide with the last output of\n",
    "# RNN for each time step. Repeat 'DIGITS + 1' times as that's the maximum\n",
    "# length of output, e.g., when DIGITS=3, max output is 999+999=1998.\n",
    "model.add(layers.RepeatVector(DIGITS + 1))\n",
    "# The decoder RNN could be multiple layers stacked or a single layer.\n",
    "for _ in range(num_layers):\n",
    "    # By setting return_sequences to True, return not only the last output but\n",
    "    # all the outputs so far in the form of (num_samples, timesteps,\n",
    "    # output_dim). This is necessary as TimeDistributed in the below expects\n",
    "    # the first dimension to be the timesteps.\n",
    "    model.add(layers.LSTM(128, return_sequences=True))\n",
    "\n",
    "# Apply a dense layer to the every temporal slice of an input. For each of step\n",
    "# of the output sequence, decide which character should be chosen.\n",
    "model.add(layers.Dense(len(chars), activation=\"softmax\"))\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d2ecc360-a39c-4939-9659-5987c91e6494",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1762261071.257051   14487 cuda_dnn.cc:529] Loaded cuDNN version 91400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.3529 - loss: 1.7739 - val_accuracy: 0.4046 - val_loss: 1.5779\n",
      "Q 124+870 T 994  \u001b[91m☒ 101 \u001b[0m\n",
      "Q 935+6   T 941  \u001b[91m☒ 904 \u001b[0m\n",
      "Q 117+63  T 180  \u001b[91m☒ 271 \u001b[0m\n",
      "Q 10+18   T 28   \u001b[91m☒ 11  \u001b[0m\n",
      "Q 935+45  T 980  \u001b[91m☒ 901 \u001b[0m\n",
      "Q 503+108 T 611  \u001b[91m☒ 510 \u001b[0m\n",
      "Q 4+293   T 297  \u001b[91m☒ 441 \u001b[0m\n",
      "Q 1+239   T 240  \u001b[91m☒ 111 \u001b[0m\n",
      "Q 721+54  T 775  \u001b[91m☒ 701 \u001b[0m\n",
      "Q 28+66   T 94   \u001b[91m☒ 27  \u001b[0m\n",
      "\n",
      "Iteration 2\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.4973 - loss: 1.3408 - val_accuracy: 0.5695 - val_loss: 1.1557\n",
      "Q 25+919  T 944  \u001b[91m☒ 935 \u001b[0m\n",
      "Q 886+997 T 1883 \u001b[91m☒ 1755\u001b[0m\n",
      "Q 555+47  T 602  \u001b[91m☒ 695 \u001b[0m\n",
      "Q 21+3    T 24   \u001b[91m☒ 35  \u001b[0m\n",
      "Q 69+457  T 526  \u001b[91m☒ 525 \u001b[0m\n",
      "Q 540+846 T 1386 \u001b[91m☒ 1395\u001b[0m\n",
      "Q 37+301  T 338  \u001b[91m☒ 349 \u001b[0m\n",
      "Q 97+965  T 1062 \u001b[91m☒ 1068\u001b[0m\n",
      "Q 847+697 T 1544 \u001b[91m☒ 1655\u001b[0m\n",
      "Q 429+1   T 430  \u001b[91m☒ 422 \u001b[0m\n",
      "\n",
      "Iteration 3\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.6231 - loss: 1.0184 - val_accuracy: 0.6716 - val_loss: 0.8997\n",
      "Q 61+926  T 987  \u001b[91m☒ 990 \u001b[0m\n",
      "Q 83+798  T 881  \u001b[91m☒ 871 \u001b[0m\n",
      "Q 698+5   T 703  \u001b[91m☒ 702 \u001b[0m\n",
      "Q 175+27  T 202  \u001b[92m☑ 202 \u001b[0m\n",
      "Q 18+90   T 108  \u001b[91m☒ 102 \u001b[0m\n",
      "Q 69+35   T 104  \u001b[91m☒ 112 \u001b[0m\n",
      "Q 9+736   T 745  \u001b[91m☒ 749 \u001b[0m\n",
      "Q 489+72  T 561  \u001b[91m☒ 562 \u001b[0m\n",
      "Q 23+335  T 358  \u001b[91m☒ 362 \u001b[0m\n",
      "Q 878+39  T 917  \u001b[91m☒ 910 \u001b[0m\n",
      "\n",
      "Iteration 4\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.6956 - loss: 0.8327 - val_accuracy: 0.7227 - val_loss: 0.7700\n",
      "Q 956+561 T 1517 \u001b[91m☒ 1521\u001b[0m\n",
      "Q 0+955   T 955  \u001b[91m☒ 953 \u001b[0m\n",
      "Q 835+996 T 1831 \u001b[91m☒ 1838\u001b[0m\n",
      "Q 224+47  T 271  \u001b[91m☒ 279 \u001b[0m\n",
      "Q 964+4   T 968  \u001b[91m☒ 967 \u001b[0m\n",
      "Q 808+26  T 834  \u001b[91m☒ 839 \u001b[0m\n",
      "Q 96+14   T 110  \u001b[91m☒ 118 \u001b[0m\n",
      "Q 972+68  T 1040 \u001b[91m☒ 1031\u001b[0m\n",
      "Q 772+5   T 777  \u001b[92m☑ 777 \u001b[0m\n",
      "Q 66+75   T 141  \u001b[91m☒ 145 \u001b[0m\n",
      "\n",
      "Iteration 5\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.7373 - loss: 0.7245 - val_accuracy: 0.7358 - val_loss: 0.7077\n",
      "Q 780+57  T 837  \u001b[91m☒ 836 \u001b[0m\n",
      "Q 797+560 T 1357 \u001b[91m☒ 1354\u001b[0m\n",
      "Q 649+7   T 656  \u001b[91m☒ 655 \u001b[0m\n",
      "Q 40+713  T 753  \u001b[91m☒ 758 \u001b[0m\n",
      "Q 60+9    T 69   \u001b[92m☑ 69  \u001b[0m\n",
      "Q 801+7   T 808  \u001b[92m☑ 808 \u001b[0m\n",
      "Q 822+18  T 840  \u001b[91m☒ 849 \u001b[0m\n",
      "Q 71+381  T 452  \u001b[91m☒ 456 \u001b[0m\n",
      "Q 296+28  T 324  \u001b[92m☑ 324 \u001b[0m\n",
      "Q 57+17   T 74   \u001b[91m☒ 84  \u001b[0m\n",
      "\n",
      "Iteration 6\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.7785 - loss: 0.6149 - val_accuracy: 0.8008 - val_loss: 0.5412\n",
      "Q 758+651 T 1409 \u001b[91m☒ 1400\u001b[0m\n",
      "Q 120+89  T 209  \u001b[92m☑ 209 \u001b[0m\n",
      "Q 142+323 T 465  \u001b[91m☒ 466 \u001b[0m\n",
      "Q 6+235   T 241  \u001b[91m☒ 240 \u001b[0m\n",
      "Q 98+317  T 415  \u001b[91m☒ 416 \u001b[0m\n",
      "Q 750+484 T 1234 \u001b[91m☒ 1246\u001b[0m\n",
      "Q 52+753  T 805  \u001b[91m☒ 806 \u001b[0m\n",
      "Q 64+423  T 487  \u001b[92m☑ 487 \u001b[0m\n",
      "Q 643+359 T 1002 \u001b[92m☑ 1002\u001b[0m\n",
      "Q 526+776 T 1302 \u001b[91m☒ 1300\u001b[0m\n",
      "\n",
      "Iteration 7\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.8740 - loss: 0.3791 - val_accuracy: 0.9148 - val_loss: 0.2882\n",
      "Q 898+977 T 1875 \u001b[92m☑ 1875\u001b[0m\n",
      "Q 34+495  T 529  \u001b[92m☑ 529 \u001b[0m\n",
      "Q 834+898 T 1732 \u001b[92m☑ 1732\u001b[0m\n",
      "Q 64+807  T 871  \u001b[91m☒ 872 \u001b[0m\n",
      "Q 75+843  T 918  \u001b[92m☑ 918 \u001b[0m\n",
      "Q 613+82  T 695  \u001b[92m☑ 695 \u001b[0m\n",
      "Q 869+977 T 1846 \u001b[91m☒ 1836\u001b[0m\n",
      "Q 41+369  T 410  \u001b[92m☑ 410 \u001b[0m\n",
      "Q 415+422 T 837  \u001b[91m☒ 847 \u001b[0m\n",
      "Q 81+24   T 105  \u001b[91m☒ 104 \u001b[0m\n",
      "\n",
      "Iteration 8\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9412 - loss: 0.2178 - val_accuracy: 0.9385 - val_loss: 0.2071\n",
      "Q 9+404   T 413  \u001b[92m☑ 413 \u001b[0m\n",
      "Q 498+199 T 697  \u001b[91m☒ 687 \u001b[0m\n",
      "Q 48+20   T 68   \u001b[92m☑ 68  \u001b[0m\n",
      "Q 545+307 T 852  \u001b[92m☑ 852 \u001b[0m\n",
      "Q 701+648 T 1349 \u001b[91m☒ 1359\u001b[0m\n",
      "Q 633+78  T 711  \u001b[92m☑ 711 \u001b[0m\n",
      "Q 296+690 T 986  \u001b[91m☒ 977 \u001b[0m\n",
      "Q 557+15  T 572  \u001b[92m☑ 572 \u001b[0m\n",
      "Q 80+95   T 175  \u001b[92m☑ 175 \u001b[0m\n",
      "Q 151+48  T 199  \u001b[91m☒ 299 \u001b[0m\n",
      "\n",
      "Iteration 9\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9667 - loss: 0.1393 - val_accuracy: 0.9779 - val_loss: 0.1102\n",
      "Q 479+14  T 493  \u001b[92m☑ 493 \u001b[0m\n",
      "Q 2+381   T 383  \u001b[92m☑ 383 \u001b[0m\n",
      "Q 37+559  T 596  \u001b[92m☑ 596 \u001b[0m\n",
      "Q 29+19   T 48   \u001b[91m☒ 47  \u001b[0m\n",
      "Q 708+83  T 791  \u001b[92m☑ 791 \u001b[0m\n",
      "Q 75+843  T 918  \u001b[92m☑ 918 \u001b[0m\n",
      "Q 90+702  T 792  \u001b[92m☑ 792 \u001b[0m\n",
      "Q 845+4   T 849  \u001b[92m☑ 849 \u001b[0m\n",
      "Q 205+13  T 218  \u001b[92m☑ 218 \u001b[0m\n",
      "Q 924+39  T 963  \u001b[92m☑ 963 \u001b[0m\n",
      "\n",
      "Iteration 10\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9778 - loss: 0.0971 - val_accuracy: 0.9848 - val_loss: 0.0741\n",
      "Q 30+215  T 245  \u001b[92m☑ 245 \u001b[0m\n",
      "Q 91+14   T 105  \u001b[92m☑ 105 \u001b[0m\n",
      "Q 365+9   T 374  \u001b[92m☑ 374 \u001b[0m\n",
      "Q 0+835   T 835  \u001b[92m☑ 835 \u001b[0m\n",
      "Q 658+174 T 832  \u001b[92m☑ 832 \u001b[0m\n",
      "Q 1+858   T 859  \u001b[91m☒ 869 \u001b[0m\n",
      "Q 71+408  T 479  \u001b[92m☑ 479 \u001b[0m\n",
      "Q 358+625 T 983  \u001b[92m☑ 983 \u001b[0m\n",
      "Q 31+955  T 986  \u001b[92m☑ 986 \u001b[0m\n",
      "Q 27+551  T 578  \u001b[92m☑ 578 \u001b[0m\n",
      "\n",
      "Iteration 11\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9807 - loss: 0.0810 - val_accuracy: 0.9836 - val_loss: 0.0662\n",
      "Q 672+143 T 815  \u001b[92m☑ 815 \u001b[0m\n",
      "Q 215+769 T 984  \u001b[92m☑ 984 \u001b[0m\n",
      "Q 420+76  T 496  \u001b[92m☑ 496 \u001b[0m\n",
      "Q 707+0   T 707  \u001b[92m☑ 707 \u001b[0m\n",
      "Q 979+66  T 1045 \u001b[92m☑ 1045\u001b[0m\n",
      "Q 742+890 T 1632 \u001b[91m☒ 1631\u001b[0m\n",
      "Q 71+665  T 736  \u001b[92m☑ 736 \u001b[0m\n",
      "Q 35+977  T 1012 \u001b[92m☑ 1012\u001b[0m\n",
      "Q 746+49  T 795  \u001b[92m☑ 795 \u001b[0m\n",
      "Q 1+806   T 807  \u001b[92m☑ 807 \u001b[0m\n",
      "\n",
      "Iteration 12\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9846 - loss: 0.0632 - val_accuracy: 0.9803 - val_loss: 0.0693\n",
      "Q 741+687 T 1428 \u001b[92m☑ 1428\u001b[0m\n",
      "Q 7+622   T 629  \u001b[91m☒ 639 \u001b[0m\n",
      "Q 61+612  T 673  \u001b[92m☑ 673 \u001b[0m\n",
      "Q 2+73    T 75   \u001b[92m☑ 75  \u001b[0m\n",
      "Q 0+994   T 994  \u001b[92m☑ 994 \u001b[0m\n",
      "Q 55+565  T 620  \u001b[92m☑ 620 \u001b[0m\n",
      "Q 982+759 T 1741 \u001b[91m☒ 1751\u001b[0m\n",
      "Q 218+589 T 807  \u001b[92m☑ 807 \u001b[0m\n",
      "Q 850+36  T 886  \u001b[92m☑ 886 \u001b[0m\n",
      "Q 992+168 T 1160 \u001b[92m☑ 1160\u001b[0m\n",
      "\n",
      "Iteration 13\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9869 - loss: 0.0521 - val_accuracy: 0.9941 - val_loss: 0.0333\n",
      "Q 936+55  T 991  \u001b[92m☑ 991 \u001b[0m\n",
      "Q 67+380  T 447  \u001b[92m☑ 447 \u001b[0m\n",
      "Q 696+51  T 747  \u001b[92m☑ 747 \u001b[0m\n",
      "Q 186+44  T 230  \u001b[92m☑ 230 \u001b[0m\n",
      "Q 802+608 T 1410 \u001b[92m☑ 1410\u001b[0m\n",
      "Q 96+809  T 905  \u001b[92m☑ 905 \u001b[0m\n",
      "Q 78+618  T 696  \u001b[92m☑ 696 \u001b[0m\n",
      "Q 48+8    T 56   \u001b[92m☑ 56  \u001b[0m\n",
      "Q 950+0   T 950  \u001b[92m☑ 950 \u001b[0m\n",
      "Q 6+258   T 264  \u001b[92m☑ 264 \u001b[0m\n",
      "\n",
      "Iteration 14\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9904 - loss: 0.0396 - val_accuracy: 0.9888 - val_loss: 0.0455\n",
      "Q 151+48  T 199  \u001b[92m☑ 199 \u001b[0m\n",
      "Q 755+257 T 1012 \u001b[92m☑ 1012\u001b[0m\n",
      "Q 67+380  T 447  \u001b[92m☑ 447 \u001b[0m\n",
      "Q 2+74    T 76   \u001b[92m☑ 76  \u001b[0m\n",
      "Q 94+66   T 160  \u001b[92m☑ 160 \u001b[0m\n",
      "Q 70+110  T 180  \u001b[92m☑ 180 \u001b[0m\n",
      "Q 630+899 T 1529 \u001b[92m☑ 1529\u001b[0m\n",
      "Q 91+14   T 105  \u001b[92m☑ 105 \u001b[0m\n",
      "Q 18+997  T 1015 \u001b[92m☑ 1015\u001b[0m\n",
      "Q 348+54  T 402  \u001b[92m☑ 402 \u001b[0m\n",
      "\n",
      "Iteration 15\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9893 - loss: 0.0422 - val_accuracy: 0.9695 - val_loss: 0.1062\n",
      "Q 278+93  T 371  \u001b[92m☑ 371 \u001b[0m\n",
      "Q 18+997  T 1015 \u001b[92m☑ 1015\u001b[0m\n",
      "Q 564+77  T 641  \u001b[92m☑ 641 \u001b[0m\n",
      "Q 967+4   T 971  \u001b[92m☑ 971 \u001b[0m\n",
      "Q 14+15   T 29   \u001b[91m☒ 39  \u001b[0m\n",
      "Q 6+37    T 43   \u001b[92m☑ 43  \u001b[0m\n",
      "Q 99+14   T 113  \u001b[92m☑ 113 \u001b[0m\n",
      "Q 506+995 T 1501 \u001b[92m☑ 1501\u001b[0m\n",
      "Q 291+726 T 1017 \u001b[92m☑ 1017\u001b[0m\n",
      "Q 333+50  T 383  \u001b[92m☑ 383 \u001b[0m\n",
      "\n",
      "Iteration 16\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9936 - loss: 0.0272 - val_accuracy: 0.9683 - val_loss: 0.1041\n",
      "Q 940+70  T 1010 \u001b[92m☑ 1010\u001b[0m\n",
      "Q 285+34  T 319  \u001b[92m☑ 319 \u001b[0m\n",
      "Q 71+468  T 539  \u001b[92m☑ 539 \u001b[0m\n",
      "Q 839+745 T 1584 \u001b[92m☑ 1584\u001b[0m\n",
      "Q 246+800 T 1046 \u001b[92m☑ 1046\u001b[0m\n",
      "Q 88+86   T 174  \u001b[92m☑ 174 \u001b[0m\n",
      "Q 47+897  T 944  \u001b[92m☑ 944 \u001b[0m\n",
      "Q 7+822   T 829  \u001b[91m☒ 839 \u001b[0m\n",
      "Q 58+46   T 104  \u001b[92m☑ 104 \u001b[0m\n",
      "Q 448+708 T 1156 \u001b[92m☑ 1156\u001b[0m\n",
      "\n",
      "Iteration 17\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9928 - loss: 0.0288 - val_accuracy: 0.9728 - val_loss: 0.0777\n",
      "Q 5+229   T 234  \u001b[92m☑ 234 \u001b[0m\n",
      "Q 863+191 T 1054 \u001b[92m☑ 1054\u001b[0m\n",
      "Q 38+804  T 842  \u001b[92m☑ 842 \u001b[0m\n",
      "Q 405+7   T 412  \u001b[92m☑ 412 \u001b[0m\n",
      "Q 146+486 T 632  \u001b[92m☑ 632 \u001b[0m\n",
      "Q 286+96  T 382  \u001b[92m☑ 382 \u001b[0m\n",
      "Q 23+96   T 119  \u001b[92m☑ 119 \u001b[0m\n",
      "Q 35+523  T 558  \u001b[92m☑ 558 \u001b[0m\n",
      "Q 57+113  T 170  \u001b[92m☑ 170 \u001b[0m\n",
      "Q 5+949   T 954  \u001b[92m☑ 954 \u001b[0m\n",
      "\n",
      "Iteration 18\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9886 - loss: 0.0418 - val_accuracy: 0.9985 - val_loss: 0.0111\n",
      "Q 955+96  T 1051 \u001b[92m☑ 1051\u001b[0m\n",
      "Q 807+67  T 874  \u001b[92m☑ 874 \u001b[0m\n",
      "Q 860+418 T 1278 \u001b[92m☑ 1278\u001b[0m\n",
      "Q 397+75  T 472  \u001b[92m☑ 472 \u001b[0m\n",
      "Q 570+48  T 618  \u001b[92m☑ 618 \u001b[0m\n",
      "Q 90+72   T 162  \u001b[92m☑ 162 \u001b[0m\n",
      "Q 924+39  T 963  \u001b[92m☑ 963 \u001b[0m\n",
      "Q 0+39    T 39   \u001b[91m☒ 49  \u001b[0m\n",
      "Q 782+10  T 792  \u001b[92m☑ 792 \u001b[0m\n",
      "Q 779+71  T 850  \u001b[92m☑ 850 \u001b[0m\n",
      "\n",
      "Iteration 19\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9895 - loss: 0.0365 - val_accuracy: 0.9977 - val_loss: 0.0138\n",
      "Q 57+704  T 761  \u001b[92m☑ 761 \u001b[0m\n",
      "Q 130+23  T 153  \u001b[92m☑ 153 \u001b[0m\n",
      "Q 739+397 T 1136 \u001b[92m☑ 1136\u001b[0m\n",
      "Q 35+54   T 89   \u001b[92m☑ 89  \u001b[0m\n",
      "Q 206+396 T 602  \u001b[92m☑ 602 \u001b[0m\n",
      "Q 92+525  T 617  \u001b[92m☑ 617 \u001b[0m\n",
      "Q 125+53  T 178  \u001b[92m☑ 178 \u001b[0m\n",
      "Q 827+145 T 972  \u001b[92m☑ 972 \u001b[0m\n",
      "Q 745+3   T 748  \u001b[92m☑ 748 \u001b[0m\n",
      "Q 0+448   T 448  \u001b[92m☑ 448 \u001b[0m\n",
      "\n",
      "Iteration 20\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9949 - loss: 0.0198 - val_accuracy: 0.9936 - val_loss: 0.0246\n",
      "Q 233+56  T 289  \u001b[92m☑ 289 \u001b[0m\n",
      "Q 381+43  T 424  \u001b[92m☑ 424 \u001b[0m\n",
      "Q 951+941 T 1892 \u001b[92m☑ 1892\u001b[0m\n",
      "Q 9+66    T 75   \u001b[92m☑ 75  \u001b[0m\n",
      "Q 35+54   T 89   \u001b[92m☑ 89  \u001b[0m\n",
      "Q 643+84  T 727  \u001b[92m☑ 727 \u001b[0m\n",
      "Q 869+8   T 877  \u001b[92m☑ 877 \u001b[0m\n",
      "Q 91+546  T 637  \u001b[92m☑ 637 \u001b[0m\n",
      "Q 69+397  T 466  \u001b[92m☑ 466 \u001b[0m\n",
      "Q 346+198 T 544  \u001b[92m☑ 544 \u001b[0m\n",
      "\n",
      "Iteration 21\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9924 - loss: 0.0278 - val_accuracy: 0.9977 - val_loss: 0.0121\n",
      "Q 156+29  T 185  \u001b[92m☑ 185 \u001b[0m\n",
      "Q 24+648  T 672  \u001b[92m☑ 672 \u001b[0m\n",
      "Q 2+140   T 142  \u001b[92m☑ 142 \u001b[0m\n",
      "Q 21+167  T 188  \u001b[92m☑ 188 \u001b[0m\n",
      "Q 20+438  T 458  \u001b[92m☑ 458 \u001b[0m\n",
      "Q 987+9   T 996  \u001b[92m☑ 996 \u001b[0m\n",
      "Q 258+1   T 259  \u001b[92m☑ 259 \u001b[0m\n",
      "Q 517+808 T 1325 \u001b[92m☑ 1325\u001b[0m\n",
      "Q 81+133  T 214  \u001b[92m☑ 214 \u001b[0m\n",
      "Q 720+366 T 1086 \u001b[92m☑ 1086\u001b[0m\n",
      "\n",
      "Iteration 22\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9921 - loss: 0.0274 - val_accuracy: 0.9916 - val_loss: 0.0281\n",
      "Q 717+63  T 780  \u001b[92m☑ 780 \u001b[0m\n",
      "Q 324+121 T 445  \u001b[92m☑ 445 \u001b[0m\n",
      "Q 769+166 T 935  \u001b[92m☑ 935 \u001b[0m\n",
      "Q 98+98   T 196  \u001b[91m☒ 197 \u001b[0m\n",
      "Q 21+147  T 168  \u001b[92m☑ 168 \u001b[0m\n",
      "Q 71+13   T 84   \u001b[92m☑ 84  \u001b[0m\n",
      "Q 23+593  T 616  \u001b[92m☑ 616 \u001b[0m\n",
      "Q 757+507 T 1264 \u001b[92m☑ 1264\u001b[0m\n",
      "Q 892+27  T 919  \u001b[92m☑ 919 \u001b[0m\n",
      "Q 2+573   T 575  \u001b[92m☑ 575 \u001b[0m\n",
      "\n",
      "Iteration 23\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9953 - loss: 0.0185 - val_accuracy: 0.9969 - val_loss: 0.0131\n",
      "Q 299+47  T 346  \u001b[92m☑ 346 \u001b[0m\n",
      "Q 62+367  T 429  \u001b[92m☑ 429 \u001b[0m\n",
      "Q 985+59  T 1044 \u001b[92m☑ 1044\u001b[0m\n",
      "Q 872+59  T 931  \u001b[92m☑ 931 \u001b[0m\n",
      "Q 546+72  T 618  \u001b[92m☑ 618 \u001b[0m\n",
      "Q 44+351  T 395  \u001b[92m☑ 395 \u001b[0m\n",
      "Q 767+84  T 851  \u001b[92m☑ 851 \u001b[0m\n",
      "Q 586+548 T 1134 \u001b[92m☑ 1134\u001b[0m\n",
      "Q 26+411  T 437  \u001b[92m☑ 437 \u001b[0m\n",
      "Q 54+114  T 168  \u001b[92m☑ 168 \u001b[0m\n",
      "\n",
      "Iteration 24\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9932 - loss: 0.0257 - val_accuracy: 0.9946 - val_loss: 0.0210\n",
      "Q 580+803 T 1383 \u001b[92m☑ 1383\u001b[0m\n",
      "Q 936+10  T 946  \u001b[92m☑ 946 \u001b[0m\n",
      "Q 244+82  T 326  \u001b[92m☑ 326 \u001b[0m\n",
      "Q 58+143  T 201  \u001b[92m☑ 201 \u001b[0m\n",
      "Q 30+309  T 339  \u001b[92m☑ 339 \u001b[0m\n",
      "Q 751+58  T 809  \u001b[92m☑ 809 \u001b[0m\n",
      "Q 215+97  T 312  \u001b[92m☑ 312 \u001b[0m\n",
      "Q 996+7   T 1003 \u001b[92m☑ 1003\u001b[0m\n",
      "Q 40+607  T 647  \u001b[92m☑ 647 \u001b[0m\n",
      "Q 823+35  T 858  \u001b[92m☑ 858 \u001b[0m\n",
      "\n",
      "Iteration 25\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9956 - loss: 0.0165 - val_accuracy: 0.9980 - val_loss: 0.0102\n",
      "Q 2+984   T 986  \u001b[92m☑ 986 \u001b[0m\n",
      "Q 10+926  T 936  \u001b[92m☑ 936 \u001b[0m\n",
      "Q 77+202  T 279  \u001b[92m☑ 279 \u001b[0m\n",
      "Q 677+25  T 702  \u001b[92m☑ 702 \u001b[0m\n",
      "Q 275+97  T 372  \u001b[92m☑ 372 \u001b[0m\n",
      "Q 83+439  T 522  \u001b[92m☑ 522 \u001b[0m\n",
      "Q 318+98  T 416  \u001b[92m☑ 416 \u001b[0m\n",
      "Q 146+96  T 242  \u001b[92m☑ 242 \u001b[0m\n",
      "Q 627+982 T 1609 \u001b[92m☑ 1609\u001b[0m\n",
      "Q 567+58  T 625  \u001b[92m☑ 625 \u001b[0m\n",
      "\n",
      "Iteration 26\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9939 - loss: 0.0233 - val_accuracy: 0.9532 - val_loss: 0.1446\n",
      "Q 582+0   T 582  \u001b[92m☑ 582 \u001b[0m\n",
      "Q 843+862 T 1705 \u001b[91m☒ 1704\u001b[0m\n",
      "Q 9+523   T 532  \u001b[92m☑ 532 \u001b[0m\n",
      "Q 279+47  T 326  \u001b[92m☑ 326 \u001b[0m\n",
      "Q 9+719   T 728  \u001b[91m☒ 727 \u001b[0m\n",
      "Q 304+103 T 407  \u001b[92m☑ 407 \u001b[0m\n",
      "Q 299+52  T 351  \u001b[92m☑ 351 \u001b[0m\n",
      "Q 583+20  T 603  \u001b[92m☑ 603 \u001b[0m\n",
      "Q 206+890 T 1096 \u001b[92m☑ 1096\u001b[0m\n",
      "Q 534+363 T 897  \u001b[91m☒ 896 \u001b[0m\n",
      "\n",
      "Iteration 27\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9976 - loss: 0.0103 - val_accuracy: 0.9995 - val_loss: 0.0041\n",
      "Q 158+188 T 346  \u001b[92m☑ 346 \u001b[0m\n",
      "Q 294+252 T 546  \u001b[92m☑ 546 \u001b[0m\n",
      "Q 65+97   T 162  \u001b[92m☑ 162 \u001b[0m\n",
      "Q 591+45  T 636  \u001b[92m☑ 636 \u001b[0m\n",
      "Q 556+678 T 1234 \u001b[92m☑ 1234\u001b[0m\n",
      "Q 245+55  T 300  \u001b[92m☑ 300 \u001b[0m\n",
      "Q 66+545  T 611  \u001b[92m☑ 611 \u001b[0m\n",
      "Q 21+342  T 363  \u001b[92m☑ 363 \u001b[0m\n",
      "Q 1+949   T 950  \u001b[92m☑ 950 \u001b[0m\n",
      "Q 515+441 T 956  \u001b[92m☑ 956 \u001b[0m\n",
      "\n",
      "Iteration 28\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9925 - loss: 0.0265 - val_accuracy: 0.9991 - val_loss: 0.0055\n",
      "Q 39+83   T 122  \u001b[92m☑ 122 \u001b[0m\n",
      "Q 61+612  T 673  \u001b[92m☑ 673 \u001b[0m\n",
      "Q 506+448 T 954  \u001b[92m☑ 954 \u001b[0m\n",
      "Q 1+369   T 370  \u001b[92m☑ 370 \u001b[0m\n",
      "Q 110+3   T 113  \u001b[92m☑ 113 \u001b[0m\n",
      "Q 7+26    T 33   \u001b[92m☑ 33  \u001b[0m\n",
      "Q 7+760   T 767  \u001b[92m☑ 767 \u001b[0m\n",
      "Q 752+681 T 1433 \u001b[92m☑ 1433\u001b[0m\n",
      "Q 7+7     T 14   \u001b[91m☒ 13  \u001b[0m\n",
      "Q 602+71  T 673  \u001b[92m☑ 673 \u001b[0m\n",
      "\n",
      "Iteration 29\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9953 - loss: 0.0164 - val_accuracy: 0.9931 - val_loss: 0.0254\n",
      "Q 2+623   T 625  \u001b[92m☑ 625 \u001b[0m\n",
      "Q 110+792 T 902  \u001b[92m☑ 902 \u001b[0m\n",
      "Q 72+733  T 805  \u001b[92m☑ 805 \u001b[0m\n",
      "Q 706+217 T 923  \u001b[92m☑ 923 \u001b[0m\n",
      "Q 2+182   T 184  \u001b[92m☑ 184 \u001b[0m\n",
      "Q 516+3   T 519  \u001b[92m☑ 519 \u001b[0m\n",
      "Q 85+23   T 108  \u001b[92m☑ 108 \u001b[0m\n",
      "Q 343+2   T 345  \u001b[92m☑ 345 \u001b[0m\n",
      "Q 533+26  T 559  \u001b[92m☑ 559 \u001b[0m\n",
      "Q 996+91  T 1087 \u001b[92m☑ 1087\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Training parameters.\n",
    "epochs = 30\n",
    "batch_size = 32\n",
    "\n",
    "# Formatting characters for results display.\n",
    "green_color = \"\\033[92m\"\n",
    "red_color = \"\\033[91m\"\n",
    "end_char = \"\\033[0m\"\n",
    "\n",
    "# Train the model each generation and show predictions against the validation\n",
    "# dataset.\n",
    "for epoch in range(1, epochs):\n",
    "    print()\n",
    "    print(\"Iteration\", epoch)\n",
    "    model.fit(\n",
    "        x_train,\n",
    "        y_train,\n",
    "        batch_size=batch_size,\n",
    "        epochs=1,\n",
    "        validation_data=(x_val, y_val),\n",
    "    )\n",
    "    # Select 10 samples from the validation set at random so we can visualize\n",
    "    # errors.\n",
    "    for i in range(10):\n",
    "        ind = np.random.randint(0, len(x_val))\n",
    "        rowx, rowy = x_val[np.array([ind])], y_val[np.array([ind])]\n",
    "        preds = np.argmax(model.predict(rowx, verbose=0), axis=-1)\n",
    "        q = ctable.decode(rowx[0])\n",
    "        correct = ctable.decode(rowy[0])\n",
    "        guess = ctable.decode(preds[0], calc_argmax=False)\n",
    "        print(\"Q\", q[::-1] if REVERSE else q, end=\" \")\n",
    "        print(\"T\", correct, end=\" \")\n",
    "        if correct == guess:\n",
    "            print(f\"{green_color}☑ {guess}{end_char}\")\n",
    "        else:\n",
    "            print(f\"{red_color}☒ {guess}{end_char}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "451193ec-68e5-477e-9dd5-81b764be3dc4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9faff164-a476-4454-8371-255792fa23d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c1ad169-bf8e-474a-ab22-fd845ba3a0ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0699d21-0da6-4311-b9b6-fd7097ae1358",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1b38515-1df5-400c-a199-4a527bbc3915",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faf304b8-3a27-445e-9dd3-4b9628729bee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f61d79f-9a47-494c-85ae-3d9cced52946",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3358636-8f53-4744-b708-db33d53ce622",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aa00ab4-9647-4661-b301-2c5e4f406704",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcca1f35-fbd9-4f27-93ab-64e637e70331",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f42153f-c1e4-4d3a-b0ea-486e6e3ff5b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be6d2572-1658-445e-83ee-54d09060b96e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fedd7a0b-d80a-4aae-9f0b-79bf79f95062",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aded0af0-a75c-48a6-9f75-34f1476c78f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "084abb82-8ab9-444d-a630-70c2df989108",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ac07283-86bf-47f4-8f41-2212829d4ecb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e58c3fe1-059c-474f-9cc8-bd1f9d961c0a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b11981d-fbf7-4a09-9fa2-33d071d7ec05",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a493c747-0689-4c51-8451-92c15806d919",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa3257ca-c96c-43e1-a128-ec602363fbec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd929cf0-d9c2-4cc4-a122-d981061eae5e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50acbdec-6ab1-4804-83ec-a199db681f7f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b73e453-be4f-4460-a221-e77897691a16",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c371f1cc-d2bd-402d-8cda-86d5bad4cece",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "208dcf5d-674e-470c-ac0c-67d51998bd37",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6e8ed9d-aa60-4a4b-876e-3a5cf7477d57",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a13b46f-82c4-4587-a348-9eac5c5c31be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbbc2003-0274-4b47-b30a-347fe974b614",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faff3e5a-466d-4a56-a07a-a2499529ad47",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd815f7a-6fe6-4d2f-bd2f-56136f77260d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3743c88-ff91-4528-8aa0-0b2e903bf272",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e56e427c-1f64-4158-9522-fee194eba1fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0a9c8e9-c44f-44d3-8d8a-615549c708c5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
