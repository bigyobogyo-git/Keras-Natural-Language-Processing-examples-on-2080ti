{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c6cdca9a-0d00-4337-8600-d3a4e5d63fc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-03 10:32:08.733935: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1762162328.745642   20874 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1762162328.749389   20874 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1762162328.759598   20874 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1762162328.759608   20874 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1762162328.759609   20874 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1762162328.759610   20874 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-11-03 10:32:08.762872: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras import ops\n",
    "from keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "776dc3f9-359f-4fb3-a426-5b284e998fdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000 Training sequences\n",
      "25000 Validation sequences\n"
     ]
    }
   ],
   "source": [
    "vocab_size = 20000  # Only consider the top 20k words\n",
    "num_tokens_per_example = 200  # Only consider the first 200 words of each movie review\n",
    "(x_train, y_train), (x_val, y_val) = keras.datasets.imdb.load_data(num_words=vocab_size)\n",
    "print(len(x_train), \"Training sequences\")\n",
    "print(len(x_val), \"Validation sequences\")\n",
    "x_train = keras.utils.pad_sequences(x_train, maxlen=num_tokens_per_example)\n",
    "x_val = keras.utils.pad_sequences(x_val, maxlen=num_tokens_per_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "80c0d92d-7817-4717-bbd6-33e6ffa15ade",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tokens per batch: 10000\n"
     ]
    }
   ],
   "source": [
    "embed_dim = 32  # Embedding size for each token.\n",
    "num_heads = 2  # Number of attention heads\n",
    "ff_dim = 32  # Hidden layer size in feedforward network.\n",
    "num_experts = 10  # Number of experts used in the Switch Transformer.\n",
    "batch_size = 50  # Batch size.\n",
    "learning_rate = 0.001  # Learning rate.\n",
    "dropout_rate = 0.25  # Dropout rate.\n",
    "num_epochs = 3  # Number of epochs.\n",
    "num_tokens_per_batch = (\n",
    "    batch_size * num_tokens_per_example\n",
    ")  # Total number of tokens per batch.\n",
    "print(f\"Number of tokens per batch: {num_tokens_per_batch}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ff09d2f7-63b7-44d8-8a7c-6cb5ca33390a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TokenAndPositionEmbedding(layers.Layer):\n",
    "    def __init__(self, maxlen, vocab_size, embed_dim):\n",
    "        super().__init__()\n",
    "        self.token_emb = layers.Embedding(input_dim=vocab_size, output_dim=embed_dim)\n",
    "        self.pos_emb = layers.Embedding(input_dim=maxlen, output_dim=embed_dim)\n",
    "\n",
    "    def call(self, x):\n",
    "        maxlen = ops.shape(x)[-1]\n",
    "        positions = ops.arange(start=0, stop=maxlen, step=1)\n",
    "        positions = self.pos_emb(positions)\n",
    "        x = self.token_emb(x)\n",
    "        return x + positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "caeb6644-ea98-4ff7-bc77-8ac7b50b9e41",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_feedforward_network(ff_dim, embed_dim, name=None):\n",
    "    return keras.Sequential(\n",
    "        [layers.Dense(ff_dim, activation=\"relu\"), layers.Dense(embed_dim)], name=name\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "85c127eb-460b-4550-9873-2814a387aa1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_balanced_loss(router_probs, expert_mask):\n",
    "    # router_probs [tokens_per_batch, num_experts] is the probability assigned for\n",
    "    # each expert per token. expert_mask [tokens_per_batch, num_experts] contains\n",
    "    # the expert with the highest router probability in one−hot format.\n",
    "\n",
    "    num_experts = ops.shape(expert_mask)[-1]\n",
    "    # Get the fraction of tokens routed to each expert.\n",
    "    # density is a vector of length num experts that sums to 1.\n",
    "    density = ops.mean(expert_mask, axis=0)\n",
    "    # Get fraction of probability mass assigned to each expert from the router\n",
    "    # across all tokens. density_proxy is a vector of length num experts that sums to 1.\n",
    "    density_proxy = ops.mean(router_probs, axis=0)\n",
    "    # Want both vectors to have uniform allocation (1/num experts) across all\n",
    "    # num_expert elements. The two vectors will be pushed towards uniform allocation\n",
    "    # when the dot product is minimized.\n",
    "    loss = ops.mean(density_proxy * density) * ops.cast((num_experts**2), \"float32\")\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "edfa0c24-8c81-4683-bdfc-0215f3491687",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Router(layers.Layer):\n",
    "    def __init__(self, num_experts, expert_capacity):\n",
    "        self.num_experts = num_experts\n",
    "        self.route = layers.Dense(units=num_experts)\n",
    "        self.expert_capacity = expert_capacity\n",
    "        super().__init__()\n",
    "\n",
    "    def call(self, inputs, training=False):\n",
    "        # inputs shape: [tokens_per_batch, embed_dim]\n",
    "        # router_logits shape: [tokens_per_batch, num_experts]\n",
    "        router_logits = self.route(inputs)\n",
    "\n",
    "        if training:\n",
    "            # Add noise for exploration across experts.\n",
    "            router_logits += keras.random.uniform(\n",
    "                shape=router_logits.shape, minval=0.9, maxval=1.1\n",
    "            )\n",
    "        # Probabilities for each token of what expert it should be sent to.\n",
    "        router_probs = keras.activations.softmax(router_logits, axis=-1)\n",
    "        # Get the top−1 expert for each token. expert_gate is the top−1 probability\n",
    "        # from the router for each token. expert_index is what expert each token\n",
    "        # is going to be routed to.\n",
    "        expert_gate, expert_index = ops.top_k(router_probs, k=1)\n",
    "        # expert_mask shape: [tokens_per_batch, num_experts]\n",
    "        expert_mask = ops.one_hot(expert_index, self.num_experts)\n",
    "        # Compute load balancing loss.\n",
    "        aux_loss = load_balanced_loss(router_probs, expert_mask)\n",
    "        self.add_loss(aux_loss)\n",
    "        # Experts have a fixed capacity, ensure we do not exceed it. Construct\n",
    "        # the batch indices, to each expert, with position in expert make sure that\n",
    "        # not more that expert capacity examples can be routed to each expert.\n",
    "        position_in_expert = ops.cast(\n",
    "            ops.cumsum(expert_mask, axis=0) * expert_mask, \"int32\"\n",
    "        )\n",
    "        # Keep only tokens that fit within expert capacity.\n",
    "        expert_mask *= ops.cast(\n",
    "            ops.less(ops.cast(position_in_expert, \"int32\"), self.expert_capacity),\n",
    "            \"float32\",\n",
    "        )\n",
    "        expert_mask_flat = ops.sum(expert_mask, axis=-1)\n",
    "        # Mask out the experts that have overflowed the expert capacity.\n",
    "        expert_gate *= expert_mask_flat\n",
    "        # Combine expert outputs and scaling with router probability.\n",
    "        # combine_tensor shape: [tokens_per_batch, num_experts, expert_capacity]\n",
    "        combined_tensor = ops.expand_dims(\n",
    "            expert_gate\n",
    "            * expert_mask_flat\n",
    "            * ops.squeeze(ops.one_hot(expert_index, self.num_experts), 1),\n",
    "            -1,\n",
    "        ) * ops.squeeze(ops.one_hot(position_in_expert, self.expert_capacity), 1)\n",
    "        # Create binary dispatch_tensor [tokens_per_batch, num_experts, expert_capacity]\n",
    "        # that is 1 if the token gets routed to the corresponding expert.\n",
    "        dispatch_tensor = ops.cast(combined_tensor, \"float32\")\n",
    "\n",
    "        return dispatch_tensor, combined_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c3ab4349-79c8-423d-a146-efd23cb75204",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Switch(layers.Layer):\n",
    "    def __init__(\n",
    "        self, num_experts, embed_dim, ff_dim, num_tokens_per_batch, capacity_factor=1\n",
    "    ):\n",
    "        self.num_experts = num_experts\n",
    "        self.embed_dim = embed_dim\n",
    "        self.experts = [\n",
    "            create_feedforward_network(ff_dim, embed_dim) for _ in range(num_experts)\n",
    "        ]\n",
    "\n",
    "        self.expert_capacity = num_tokens_per_batch // self.num_experts\n",
    "        self.router = Router(self.num_experts, self.expert_capacity)\n",
    "        super().__init__()\n",
    "\n",
    "    def call(self, inputs):\n",
    "        batch_size = ops.shape(inputs)[0]\n",
    "        num_tokens_per_example = ops.shape(inputs)[1]\n",
    "\n",
    "        # inputs shape: [num_tokens_per_batch, embed_dim]\n",
    "        inputs = ops.reshape(inputs, [num_tokens_per_batch, self.embed_dim])\n",
    "        # dispatch_tensor shape: [expert_capacity, num_experts, tokens_per_batch]\n",
    "        # combine_tensor shape: [tokens_per_batch, num_experts, expert_capacity]\n",
    "        dispatch_tensor, combine_tensor = self.router(inputs)\n",
    "        # expert_inputs shape: [num_experts, expert_capacity, embed_dim]\n",
    "        expert_inputs = ops.einsum(\"ab,acd->cdb\", inputs, dispatch_tensor)\n",
    "        expert_inputs = ops.reshape(\n",
    "            expert_inputs, [self.num_experts, self.expert_capacity, self.embed_dim]\n",
    "        )\n",
    "        # Dispatch to experts\n",
    "        expert_input_list = ops.unstack(expert_inputs, axis=0)\n",
    "        expert_output_list = [\n",
    "            self.experts[idx](expert_input)\n",
    "            for idx, expert_input in enumerate(expert_input_list)\n",
    "        ]\n",
    "        # expert_outputs shape: [expert_capacity, num_experts, embed_dim]\n",
    "        expert_outputs = ops.stack(expert_output_list, axis=1)\n",
    "        # expert_outputs_combined shape: [tokens_per_batch, embed_dim]\n",
    "        expert_outputs_combined = ops.einsum(\n",
    "            \"abc,xba->xc\", expert_outputs, combine_tensor\n",
    "        )\n",
    "        # output shape: [batch_size, num_tokens_per_example, embed_dim]\n",
    "        outputs = ops.reshape(\n",
    "            expert_outputs_combined,\n",
    "            [batch_size, num_tokens_per_example, self.embed_dim],\n",
    "        )\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "762263ec-786f-4efc-ba67-84a1496488a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerBlock(layers.Layer):\n",
    "    def __init__(self, embed_dim, num_heads, ffn, dropout_rate=0.1):\n",
    "        super().__init__()\n",
    "        self.att = layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n",
    "        # The ffn can be either a standard feedforward network or a switch\n",
    "        # layer with a Mixture of Experts.\n",
    "        self.ffn = ffn\n",
    "        self.layernorm1 = layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.dropout1 = layers.Dropout(dropout_rate)\n",
    "        self.dropout2 = layers.Dropout(dropout_rate)\n",
    "\n",
    "    def call(self, inputs, training=False):\n",
    "        attn_output = self.att(inputs, inputs)\n",
    "        attn_output = self.dropout1(attn_output, training=training)\n",
    "        out1 = self.layernorm1(inputs + attn_output)\n",
    "        ffn_output = self.ffn(out1)\n",
    "        ffn_output = self.dropout2(ffn_output, training=training)\n",
    "        return self.layernorm2(out1 + ffn_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "50682e30-3ccb-4934-8f14-75ba2f4c4b01",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_classifier():\n",
    "    switch = Switch(num_experts, embed_dim, ff_dim, num_tokens_per_batch)\n",
    "    transformer_block = TransformerBlock(embed_dim // num_heads, num_heads, switch)\n",
    "\n",
    "    inputs = layers.Input(shape=(num_tokens_per_example,))\n",
    "    embedding_layer = TokenAndPositionEmbedding(\n",
    "        num_tokens_per_example, vocab_size, embed_dim\n",
    "    )\n",
    "    x = embedding_layer(inputs)\n",
    "    x = transformer_block(x)\n",
    "    x = layers.GlobalAveragePooling1D()(x)\n",
    "    x = layers.Dropout(dropout_rate)(x)\n",
    "    x = layers.Dense(ff_dim, activation=\"relu\")(x)\n",
    "    x = layers.Dropout(dropout_rate)(x)\n",
    "    outputs = layers.Dense(2, activation=\"softmax\")(x)\n",
    "\n",
    "    classifier = keras.Model(inputs=inputs, outputs=outputs)\n",
    "    return classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9e72bc46-46c3-46e8-9027-a0c3a349fd4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1762162333.048172   20874 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 8841 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2080 Ti, pci bus id: 0000:08:00.0, compute capability: 7.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1762162337.157943   20981 service.cc:152] XLA service 0x7faaec004b80 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1762162337.157956   20981 service.cc:160]   StreamExecutor device (0): NVIDIA GeForce RTX 2080 Ti, Compute Capability 7.5\n",
      "2025-11-03 10:32:17.248984: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "I0000 00:00:1762162337.885778   20981 cuda_dnn.cc:529] Loaded cuDNN version 91400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m 12/500\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 16ms/step - accuracy: 0.5378 - loss: 1.7342"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1762162342.264917   20981 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 24ms/step - accuracy: 0.7962 - loss: 1.4288 - val_accuracy: 0.8768 - val_loss: 1.2932\n",
      "Epoch 2/3\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 26ms/step - accuracy: 0.9178 - loss: 1.2147 - val_accuracy: 0.8660 - val_loss: 1.3173\n",
      "Epoch 3/3\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 28ms/step - accuracy: 0.9481 - loss: 1.1421 - val_accuracy: 0.8644 - val_loss: 1.3588\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7fac00f68880>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def run_experiment(classifier):\n",
    "    classifier.compile(\n",
    "        optimizer=keras.optimizers.Adam(learning_rate),\n",
    "        loss=\"sparse_categorical_crossentropy\",\n",
    "        metrics=[\"accuracy\"],\n",
    "    )\n",
    "    history = classifier.fit(\n",
    "        x_train,\n",
    "        y_train,\n",
    "        batch_size=batch_size,\n",
    "        epochs=num_epochs,\n",
    "        validation_data=(x_val, y_val),\n",
    "    )\n",
    "    return history\n",
    "\n",
    "\n",
    "classifier = create_classifier()\n",
    "run_experiment(classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bd3710c-12a5-4c16-8fea-f13abad4133d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec29d49c-ffdb-4e6c-afd7-e88bac8a6f06",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa06fa38-a727-4555-bf00-0471cba770f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5c2912e-b324-402c-877a-20c053a6dde5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "640ff9a9-7466-4268-aceb-ba10c6ecb703",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d7a5151-e4df-4d93-9d4c-7bd106c7df8f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e13c0cc-b524-452b-b82d-2121b129ef36",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27cc8bbd-1905-4a47-9451-93498b790cb9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2afcfba-3d78-416b-a136-c9a0a16ea441",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "998a9357-af43-4fde-97bd-911d1af31be4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d01e70ee-74b8-40f9-b1be-5a4fe993d8b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f5860ec-92a2-4ef3-ad7d-125e0e48111a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
