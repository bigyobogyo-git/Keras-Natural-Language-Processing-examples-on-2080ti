{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9a4c967a-b75b-42d7-a9ff-1262d3d0e5ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-02 16:08:41.465467: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from tqdm.auto import tqdm\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "import keras_cv\n",
    "from keras_cv import bounding_box\n",
    "from keras_cv import visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "09c1d2d6-e5ac-4f78-87ca-089017e9a6c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "SPLIT_RATIO = 0.2\n",
    "BATCH_SIZE = 4\n",
    "LEARNING_RATE = 0.001\n",
    "EPOCH = 5\n",
    "GLOBAL_CLIPNORM = 10.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "75bd87f8-8e5a-4117-98bc-fdeedf248a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_ids = [\n",
    "    \"car\",\n",
    "    \"pedestrian\",\n",
    "    \"trafficLight\",\n",
    "    \"biker\",\n",
    "    \"truck\",\n",
    "]\n",
    "class_mapping = dict(zip(range(len(class_ids)), class_ids))\n",
    "\n",
    "# Path to images and annotations\n",
    "path_images = \"export/images\"\n",
    "path_annot = \"export/labels\"\n",
    "\n",
    "# Get all XML file paths in path_annot and sort them\n",
    "xml_files = sorted(\n",
    "    [\n",
    "        os.path.join(path_annot, file_name)\n",
    "        for file_name in os.listdir(path_annot)\n",
    "        if file_name.endswith(\".xml\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Get all JPEG image file paths in path_images and sort them\n",
    "jpg_files = sorted(\n",
    "    [\n",
    "        os.path.join(path_images, file_name)\n",
    "        for file_name in os.listdir(path_images)\n",
    "        if file_name.endswith(\".jpg\")\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bf00de15-5b63-45e5-b785-f9f0d5b08e83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1eaad863a59b404296a9576322cc1f6f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def parse_annotation(xml_file):\n",
    "    tree = ET.parse(xml_file)\n",
    "    root = tree.getroot()\n",
    "\n",
    "    image_name = root.find(\"filename\").text\n",
    "    image_path = os.path.join(path_images, image_name)\n",
    "\n",
    "    boxes = []\n",
    "    classes = []\n",
    "    for obj in root.iter(\"object\"):\n",
    "        cls = obj.find(\"name\").text\n",
    "        classes.append(cls)\n",
    "\n",
    "        bbox = obj.find(\"bndbox\")\n",
    "        xmin = float(bbox.find(\"xmin\").text)\n",
    "        ymin = float(bbox.find(\"ymin\").text)\n",
    "        xmax = float(bbox.find(\"xmax\").text)\n",
    "        ymax = float(bbox.find(\"ymax\").text)\n",
    "        boxes.append([xmin, ymin, xmax, ymax])\n",
    "\n",
    "    class_ids = [\n",
    "        list(class_mapping.keys())[list(class_mapping.values()).index(cls)]\n",
    "        for cls in classes\n",
    "    ]\n",
    "    return image_path, boxes, class_ids\n",
    "\n",
    "\n",
    "image_paths = []\n",
    "bbox = []\n",
    "classes = []\n",
    "for xml_file in tqdm(xml_files):\n",
    "    image_path, boxes, class_ids = parse_annotation(xml_file)\n",
    "    image_paths.append(image_path)\n",
    "    bbox.append(boxes)\n",
    "    classes.append(class_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "58e7abdf-9270-4b3c-b778-bd0ed3e9cfc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = [\n",
    "    [8, 8, 8, 8, 8],      # 5 classes\n",
    "    [12, 14, 14, 14],     # 4 classes\n",
    "    [1],                  # 1 class\n",
    "    [7, 7],               # 2 classes\n",
    " ...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fffa21ef-7139-4b31-b705-067731f6bce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "bbox = [\n",
    "    [[199.0, 19.0, 390.0, 401.0],\n",
    "    [217.0, 15.0, 270.0, 157.0],\n",
    "    [393.0, 18.0, 432.0, 162.0],\n",
    "    [1.0, 15.0, 226.0, 276.0],\n",
    "    [19.0, 95.0, 458.0, 443.0]],     #image 1 has 4 objects\n",
    "    [[52.0, 117.0, 109.0, 177.0]],   #image 2 has 1 object\n",
    "    [[88.0, 87.0, 235.0, 322.0],\n",
    "    [113.0, 117.0, 218.0, 471.0]],   #image 3 has 2 objects\n",
    " ...]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "be3a3190-b7e2-4f84-bdc0-eed979830863",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "all scalar values must have the same nesting depth",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m bbox \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mragged\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconstant\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbbox\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m classes \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mragged\u001b[38;5;241m.\u001b[39mconstant(classes)\n\u001b[1;32m      3\u001b[0m image_paths \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mragged\u001b[38;5;241m.\u001b[39mconstant(image_paths)\n",
      "File \u001b[0;32m~/Desktop/ml/keras/test/keras_test/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m--> 153\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    155\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/Desktop/ml/keras/test/keras_test/lib/python3.10/site-packages/tensorflow/python/ops/ragged/ragged_factory_ops.py:288\u001b[0m, in \u001b[0;36m_find_scalar_and_max_depth\u001b[0;34m(pylist)\u001b[0m\n\u001b[1;32m    286\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m child_scalar_depth \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    287\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m scalar_depth \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m scalar_depth \u001b[38;5;241m!=\u001b[39m child_scalar_depth \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m--> 288\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mall scalar values must have the same nesting depth\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    289\u001b[0m   scalar_depth \u001b[38;5;241m=\u001b[39m child_scalar_depth \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    290\u001b[0m max_depth \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(max_depth, child_max_depth \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: all scalar values must have the same nesting depth"
     ]
    }
   ],
   "source": [
    "bbox = tf.ragged.constant(bbox)\n",
    "classes = tf.ragged.constant(classes)\n",
    "image_paths = tf.ragged.constant(image_paths)\n",
    "\n",
    "data = tf.data.Dataset.from_tensor_slices((image_paths, classes, bbox))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e719e0c6-2920-4ab7-af0a-02af0bc055ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3a5fcf2-8568-4784-98ec-2c5c86cc516d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3001c930-6454-4d91-880e-97a52f4bd3e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9450e67-90a3-47f5-b77d-26f128988d30",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d5259a0-d871-40cf-9809-5de490f76c92",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "195c9521-9c8c-4467-9b5f-d4fa2bdbb2ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afc854bf-df88-43a6-b82b-6e02f0a48859",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b4d6b1d-4920-475b-a063-cf1af53ba982",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20f69e23-0b0e-4032-817e-42446f22d323",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eca2786-dc3d-462b-81c2-e2773798ef7d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3937ff76-65ec-4733-a315-057e1491066b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b7151d1-fadd-44f9-80d2-c26ab61d37a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c85f45c-1aa7-4f7a-86d7-db0f624122f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94d37109-5535-4ece-a20f-c8b2e8779902",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a4ea0ae-247a-443b-b1c7-4737abe94342",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8aed59c-ccb0-47d7-9f82-0d398f8291d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd6b6371-db1c-4f8e-a8c3-5b9e69eb9825",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ec82f6d-c49a-4a91-8b5e-99407585d1ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf29889a-cbdc-4af0-b3d1-74e966cb1937",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f1a62ac-cdc0-442d-83ae-63ca440586f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59ce1e25-f41a-48bc-aab3-b17955862885",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a60934c-733e-4088-a2fd-cf4b7b9ff382",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "573ac798-26f2-4572-9261-5e3a4163a315",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdbeb6df-02ba-4c16-8e3c-77eeae6c578c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e49b1371-e903-4eae-bc74-f968f560c003",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
